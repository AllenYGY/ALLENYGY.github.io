<!DOCTYPE html> <html><head>
		<title>BDA-Project-Report - NOTE</title>
		<base href="../../../">
		<meta id="root-path" root-path="../../../">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
		<!--<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes, minimum-scale=1.0, maximum-scale=5.0">-->
		<meta charset="UTF-8">
		<meta name="description" content="BDA-Project-Report - NOTE">
		<meta property="og:title" content="BDA-Project-Report">
		<meta property="og:description" content="BDA-Project-Report - NOTE">
		<meta property="og:type" content="website">
		<meta property="og:url" content="https://allenygy.github.io/data-analysis/big-data-analysis/peoject/bda-project-report.html">
		<meta property="og:image" content="https://allenygy.github.io/data-analysis/big-data-analysis/peoject/workflow.png">
		<meta property="og:site_name" content="NOTE">
		<meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate">
		<meta http-equiv="Pragma" content="no-cache">
		<meta http-equiv="Expires" content="0">
		<meta name="ctime" content="1734044725363">
		<meta name="author" content="AllenYGY"><link rel="alternate" type="application/rss+xml" title="RSS Feed" href="https://allenygy.github.io/lib/rss.xml"><script async="" id="webpage-script" src="lib/scripts/webpage.js?v=1.8.03" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;);"></script><script id="minisearch-script" src="https://cdn.jsdelivr.net/npm/minisearch@6.3.0/dist/umd/index.min.js?v=1.8.03" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;);"></script><script defer="" id="easy-notice-script" src="lib/scripts/easy-notice.js?v=1.8.03" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;);"></script><link rel="icon" href="lib/media/favicon.png"><style>body{--line-width:40em;--line-width-adaptive:40em;--file-line-width:40em;--sidebar-width:min(20em, 80vw);--collapse-arrow-size:11px;--tree-horizontal-spacing:0.6em;--tree-vertical-spacing:0.6em;--sidebar-margin:12px}.sidebar{height:100%;min-width:calc(var(--sidebar-width) + var(--divider-width-hover));max-width:calc(var(--sidebar-width) + var(--divider-width-hover));font-size:14px;z-index:10;position:relative;overflow:hidden;transition:min-width ease-in-out,max-width ease-in-out;transition-duration:.2s;contain:size}.sidebar-left{left:0}.sidebar-right{right:0}.sidebar.is-collapsed{min-width:0;max-width:0}body.floating-sidebars .sidebar{position:absolute}.sidebar-content{height:100%;min-width:calc(var(--sidebar-width) - var(--divider-width-hover));top:0;padding:var(--sidebar-margin);padding-top:4em;line-height:var(--line-height-tight);background-color:var(--background-secondary);transition:background-color,border-right,border-left,box-shadow;transition-duration:var(--color-fade-speed);transition-timing-function:ease-in-out;position:absolute;display:flex;flex-direction:column}.sidebar:not(.is-collapsed) .sidebar-content{min-width:calc(max(100%,var(--sidebar-width)) - 3px);max-width:calc(max(100%,var(--sidebar-width)) - 3px)}.sidebar-left .sidebar-content{left:0;border-top-right-radius:var(--radius-l);border-bottom-right-radius:var(--radius-l)}.sidebar-right .sidebar-content{right:0;border-top-left-radius:var(--radius-l);border-bottom-left-radius:var(--radius-l)}.sidebar:has(.sidebar-content:empty):has(.topbar-content:empty){display:none}.sidebar-topbar{height:2em;width:var(--sidebar-width);top:var(--sidebar-margin);padding-inline:var(--sidebar-margin);z-index:1;position:fixed;display:flex;align-items:center;transition:width ease-in-out;transition-duration:inherit}.sidebar.is-collapsed .sidebar-topbar{width:calc(2.3em + var(--sidebar-margin) * 2)}.sidebar .sidebar-topbar.is-collapsed{width:0}.sidebar-left .sidebar-topbar{left:0}.sidebar-right .sidebar-topbar{right:0}.topbar-content{overflow:hidden;overflow:clip;width:100%;height:100%;display:flex;align-items:center;transition:inherit}.sidebar.is-collapsed .topbar-content{width:0;transition:inherit}.clickable-icon.sidebar-collapse-icon{background-color:transparent;color:var(--icon-color-focused);padding:0!important;margin:0!important;height:100%!important;width:2.3em!important;margin-inline:0.14em!important;position:absolute}.sidebar-left .clickable-icon.sidebar-collapse-icon{transform:rotateY(180deg);right:var(--sidebar-margin)}.sidebar-right .clickable-icon.sidebar-collapse-icon{transform:rotateY(180deg);left:var(--sidebar-margin)}.clickable-icon.sidebar-collapse-icon svg.svg-icon{width:100%;height:100%}.sidebar-section-header{margin:0 0 1em 0;text-transform:uppercase;letter-spacing:.06em;font-weight:600}body{transition:background-color var(--color-fade-speed) ease-in-out}.webpage-container{display:flex;flex-direction:row;height:100%;width:100%;align-items:stretch;justify-content:center}.document-container{opacity:1;flex-basis:100%;max-width:100%;width:100%;height:100%;display:flex;flex-direction:column;align-items:center;transition:opacity .2s ease-in-out;contain:inline-size}.hide{opacity:0;transition:opacity .2s ease-in-out}.document-container>.markdown-preview-view{margin:var(--sidebar-margin);margin-bottom:0;width:100%;width:-webkit-fill-available;width:-moz-available;width:fill-available;background-color:var(--background-primary);transition:background-color var(--color-fade-speed) ease-in-out;border-top-right-radius:var(--window-radius,var(--radius-m));border-top-left-radius:var(--window-radius,var(--radius-m));overflow-x:hidden!important;overflow-y:auto!important;display:flex!important;flex-direction:column!important;align-items:center!important;contain:inline-size}.document-container>.markdown-preview-view>.markdown-preview-sizer{padding-bottom:80vh!important;width:100%!important;max-width:var(--line-width)!important;flex-basis:var(--line-width)!important;transition:background-color var(--color-fade-speed) ease-in-out;contain:inline-size}.markdown-rendered img:not([width]),.view-content img:not([width]){max-width:100%;outline:0}.document-container>.view-content.embed{display:flex;padding:1em;height:100%;width:100%;align-items:center;justify-content:center}.document-container>.view-content.embed>*{max-width:100%;max-height:100%;object-fit:contain}:has(> :is(.math,table)){overflow-x:auto!important}.document-container>.view-content{overflow-x:auto;contain:content;padding:0;margin:0;height:100%}.scroll-highlight{position:absolute;width:100%;height:100%;pointer-events:none;z-index:1000;background-color:hsla(var(--color-accent-hsl),.25);opacity:0;padding:1em;inset:50%;translate:-50% -50%;border-radius:var(--radius-s)}</style><script defer="">async function loadIncludes(){if("file:"!=location.protocol){let e=document.querySelectorAll("include");for(let t=0;t<e.length;t++){let o=e[t],l=o.getAttribute("src");try{const e=await fetch(l);if(!e.ok){console.log("Could not include file: "+l),o?.remove();continue}let t=await e.text(),n=document.createRange().createContextualFragment(t),i=Array.from(n.children);for(let e of i)e.classList.add("hide"),e.style.transition="opacity 0.5s ease-in-out",setTimeout((()=>{e.classList.remove("hide")}),10);o.before(n),o.remove(),console.log("Included file: "+l)}catch(e){o?.remove(),console.log("Could not include file: "+l,e);continue}}}else{if(document.querySelectorAll("include").length>0){var e=document.createElement("div");e.id="error",e.textContent="Web server exports must be hosted on an http / web server to be viewed correctly.",e.style.position="fixed",e.style.top="50%",e.style.left="50%",e.style.transform="translate(-50%, -50%)",e.style.fontSize="1.5em",e.style.fontWeight="bold",e.style.textAlign="center",document.body.appendChild(e),document.querySelector(".document-container")?.classList.remove("hide")}}}document.addEventListener("DOMContentLoaded",(()=>{loadIncludes()}));let isFileProtocol="file:"==location.protocol;function waitLoadScripts(e,t){let o=e.map((e=>document.getElementById(e+"-script"))),l=0;!function e(){let n=o[l];l++,n&&"true"!=n.getAttribute("loaded")||l<o.length&&e(),l<o.length?n.addEventListener("load",e):t()}()}</script><script defer="" id="img-zoom-script" src="lib/scripts/img-zoom.js?v=1.8.03" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;);"></script><link rel="stylesheet" href="lib/styles/obsidian.css?v=1.8.03"><link rel="preload" href="lib/styles/other-plugins.css?v=1.8.03" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="lib/styles/other-plugins.css?v=1.8.03"></noscript><link rel="stylesheet" href="lib/styles/theme.css?v=1.8.03"><link rel="preload" href="lib/styles/global-variable-styles.css?v=1.8.03" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="lib/styles/global-variable-styles.css?v=1.8.03"></noscript><link rel="preload" href="lib/styles/supported-plugins.css?v=1.8.03" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="lib/styles/supported-plugins.css?v=1.8.03"></noscript><link rel="preload" href="lib/styles/main-styles.css?v=1.8.03" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="lib/styles/main-styles.css?v=1.8.03"></noscript><link rel="preload" href="lib/styles/snippets.css?v=1.8.03" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="lib/styles/snippets.css?v=1.8.03"></noscript><script>const LANG="en",VERSION="1.8.03",SHOW_COMMENTS=!1,SHOW_PAGE_HEADER=!0,SHOW_PAGE_FOOTER=!0,SHOW_RSS_FEED=!0,SHOW_SCROLL_TO_TOP=!0,SHOW_FILE_NUMBER=!0,EXPORT_PRESET="website",WALINE_SERVER_URL="",AUTHOR="AllenYGY",VAULT_TITLE="NOTE",FILE_COLORS={},DEFAULT_THEME="dark",USE_FILE_COLOR_PLUGIN=!0,USE_BARTENDER_PLUGIN=!0</script><script src="https://unpkg.com/prismjs@1.29.0/prism.js" defer="defer"></script><script src="https://unpkg.com/lucide@latest"></script><link rel="stylesheet" href="https://unpkg.com/@waline/client@v3/dist/waline.css"><link rel="stylesheet" href="https://unpkg.com/@waline/client@v3/dist/waline-meta.css"><style>body{--font-ui-medium:16px}:root{--waline-font-size:16px;--waline-white:#fff;--waline-light-grey:#999;--waline-dark-grey:#666;--waline-theme-color:#27ae60;--waline-active-color:#2ecc71;--waline-color:#444;--waline-bg-color:var(--background-primary-alt);--waline-bg-color-light:#f8f8f8;--waline-bg-color-hover:#f0f0f0;--waline-border-color:#ddd;--waline-disable-bg-color:#f8f8f8;--waline-disable-color:#bbb;--waline-code-bg-color:#282c34;--waline-bq-color:#f0f0f0;--waline-avatar-size:3.25rem;--waline-m-avatar-size:calc(var(--waline-avatar-size) * 9 / 13);--waline-badge-color:#3498db;--waline-badge-font-size:0.775em;--waline-info-bg-color:#f8f8f8;--waline-info-color:#999;--waline-info-font-size:0.625em;--waline-border:1px solid var(--waline-border-color);--waline-avatar-radius:50%;--waline-box-shadow:none}.waline-theme-dark{--waline-white:#000;--waline-light-grey:#666;--waline-dark-grey:#999;--waline-color:#888;--waline-bg-color:var(--background-primary-alt);--waline-bg-color-light:#272727;--waline-border-color:#333;--waline-disable-bg-color:#444;--waline-disable-color:#272727;--waline-bq-color:#272727;--waline-info-bg-color:#272727;--waline-info-color:#666}.wl-power{display:none}.wl-reaction{margin-bottom:1em;text-align:left;margin-left:.5em}.wl-reaction-title{margin:20px auto}.wl-reaction-list{justify-content:left}.document-container>.markdown-preview-view>.markdown-preview-sizer{padding-bottom:17px!important}.wl-panel{margin:0}#waline{margin-top:50px!important;max-width:800px}.clickable-icon.sidebar-collapse-icon{width:2em!important;background-color:var(--background-secondary)}.graph-view-placeholder{width:22%;margin-left:38px}.tree-container .clickable-icon{margin-left:2px;border-radius:5px;border:none;box-shadow:none;display:flex;align-items:center;justify-content:center;margin-top:-3px}.document-container>.markdown-preview-view>.markdown-preview-sizer{max-width:100vw!important}body.show-inline-title .page-title{text-align:center}input[type=text],textarea{font-size:16px!important}input[type=search]{width:85%;border:1px solid #888;border-radius:5px;background-color:var(--background-primary);color:var(--text-muted)}.tree-container .clickable-icon{background-color:transparent}body{user-select:unset}blockquote{margin:0}#copyright{text-align:center;margin-top:80px!important}#copyright a{color:#ee802f;text-decoration:none;font-size:15px;margin-left:4px}#copyright a img{width:14px}.document-container>.markdown-preview-view>.markdown-preview-sizer pre{overflow:auto}.theme-light .document-container>.markdown-preview-view>.markdown-preview-sizer pre{position:relative;background-color:var(--background-primary-alt);border:1px solid #eeecec;border-radius:5px;padding:10px}.theme-dark .document-container>.markdown-preview-view>.markdown-preview-sizer pre{position:relative;background-color:var(--background-primary-alt);border:1px solid #373838;border-radius:5px;padding:10px}.markdown-rendered pre button.copy-code-button{position:absolute;top:7px;right:7px}.wl-header input{font-size:16px}.wl-reaction-votes{text-align:center}html>body>.webpage-container>.document-container>.markdown-preview-view>.markdown-preview-sizer>div.page-meta{text-align:center;padding:10px!important}html>body>.webpage-container>.document-container>.markdown-preview-view>.markdown-preview-sizer>div{margin-inline:0!important;margin:0!important;padding:10%!important;width:100%;max-width:100%}.page-ctime,.waline-comment-count,.waline-pageview-count{margin-right:35px}.page-meta{color:#888}.page-meta svg{width:16px;vertical-align:middle}#qrcode{position:relative}#qr-zoom{position:absolute;width:170px;height:200px;z-index:999;display:none;border:1px solid #ccc;background:#fff}#qrcode:hover #qr-zoom{display:inline-block}#qr-zoom img{margin-top:10px}#qr-zoom font{margin-top:4px;display:inline-block}@media (max-width:768px){#qrcode{display:none!important}}#scrollToTopBtn{display:none;position:fixed;width:46px;height:46px;border:1px solid #ddd;border-radius:5px;background-color:var(--background-primary);text-align:center;bottom:75px;right:306px;opacity:.8}#scrollToTopBtn:hover{background-color:var(--background-primary-alt)}#scrollToTopBtn svg{margin-top:11px;color:var(--text-normal)}#scrollToTopBtn.st-collapsed{right:30px}@media (max-width:768px){#scrollToTopBtn{right:12px}#scrollToTopBtn.st-collapsed{right:12px}}.theme-dark #scrollToTopBtn{border:1px solid #999}.markdown-rendered pre button.copy-code-button{background-color:var(--background-primary);padding:3px 6px;border:1px solid #888;border-radius:5px;opacity:.9}.document-container.markdown-reading-view{background-color:var(--background-primary)}table{border:1px solid var(--table-border-color);border-radius:var(--size-2-3);border-spacing:0}td,th{padding:10px;border-right:1px solid var(--table-border-color);border-bottom:1px solid var(--table-border-color)}td:last-child,th:last-child{border-right:0}tr:last-child td,tr:last-child:not(:only-child) th{border-bottom:0}table>:only-child th{border-bottom:0}.document-container>.markdown-preview-view{margin:0;padding:var(--sidebar-margin)}.sidebar-content{background-color:var(--background-primary-alt)}.nav-folder-title[data-count]::after{content:attr(data-count);font-size:calc(100% * .8);margin-right:12px}.tree-container .tree-header{width:100%}#total-files{position:absolute;right:12px;color:var(--nav-item-color);font-size:calc(100% * .8)}.tree-container .collapse-icon{display:flex;align-items:center}.internal-embed.file-embed{cursor:pointer}.sidebar-content{padding-left:0;padding-right:0}.search-input-container{padding-left:10px}.tree-container{padding-left:12px;padding-right:12px}.graph-view-wrapper{padding-left:12px;padding-right:12px}.tree-container .tree-header,body .webpage-container .tree-container .tree-scroll-area{width:calc(100% - 12px)}.tree-container .clickable-icon svg{width:18px}ul.dataview.list-view-ul li{line-height:180%}#webpage-icon{display:none}.markdown-reading-view table{margin-block-start:var(--p-spacing);margin-block-end:var(--p-spacing)}li{line-height:180%}</style><script type="module">import{init}from"https://unpkg.com/@waline/client@v3/dist/waline.js";window.initWaline=e=>{e=e||document;const t=location.pathname.replace(/index\.html$/,"").replace(/\/$/,"")||"/",o=document.querySelector("#waline"),n=document.querySelector(".markdown-preview-sizer");if(!o){const e=document.createElement("div");e.id="waline",SHOW_COMMENTS||(e.style.display="none"),n.appendChild(e)}let i=document.querySelector(".page-meta");if(!i){const o=document.querySelector(".page-title");i=document.createElement("div"),i.className="page-meta",SHOW_PAGE_HEADER||(i.style.display="none");const n=e.querySelector('meta[name="ctime"]')?.getAttribute("content")||"";let c='<span title="创建时间"><i data-lucide="clock"></i> <span class="page-ctime">'+timestampToTimeString(+n)+"</span></span> ";SHOW_COMMENTS&&(c+='<span title="评论量"><i data-lucide="message-circle-more"></i> <span class="waline-comment-count" data-path="'+t+'">0</span></span> '),c+='<span title="阅读量"><i data-lucide="eye"></i> <span class="waline-pageview-count" data-path="'+t+'">1</span></span> ',c+='<span id="qrcode" title="手机查看"><i data-lucide="qr-code"></i><span id="qr-zoom"><img src="https://api.qrserver.com/v1/create-qr-code/?size=150x150&data='+encodeURIComponent(location.href)+'" /><br /><font>手机查看</font></span></span>',i.innerHTML=c,o.after(i),lucide.createIcons()}try{(SHOW_PAGE_HEADER||SHOW_COMMENTS)&&init({el:"#waline",reaction:!0,dark:!1,copyright:!1,pageview:!0,comment:!0,path:t,serverURL:WALINE_SERVER_URL||"",locale:{reaction0:"点赞",reaction1:"踩一下",reaction2:"酷毙了",reaction3:"不屑",reaction4:"尴尬",reaction5:"无聊"}})}catch(e){console.log(e)}if(SHOW_SCROLL_TO_TOP&&!document.getElementById("scrollToTop")){const e=document.createElement("div");e.id="scrollToTop",e.innerHTML='<div id="scrollToTopBtn"><i data-lucide="arrow-up-to-line"></i></div>',n.appendChild(e),lucide.createIcons();var c=document.querySelector(".document-container>.markdown-preview-view"),a=document.getElementById("scrollToTopBtn");c.addEventListener("scroll",(function(){var e=c.scrollTop,t=.25*c.clientHeight;a.style.display=e>t?"block":"none"})),a.addEventListener("click",(function(){var e=document.querySelector(".document-container>.markdown-preview-view");"scrollBehavior"in document.documentElement.style?e.scrollTo({top:0,behavior:"smooth"}):e.scrollTop=0})),onToggleCollapsedChangedToTop();document.querySelector(".sidebar-right .clickable-icon.sidebar-collapse-icon").addEventListener("click",(()=>{setTimeout((()=>{onToggleCollapsedChangedToTop()}),42)}))}document.querySelectorAll(".document-container>.markdown-preview-view>.markdown-preview-sizer pre").forEach((e=>{e.addEventListener("scroll",(()=>{const t=e.querySelector(".copy-code-button"),o=t.getBoundingClientRect();t.style.right="auto",t.style.left=e.scrollLeft+e.offsetWidth-o.width-8+"px"}))})),setTimeout((()=>{if(!SHOW_COMMENTS)return;const e=document.querySelector(".wl-count");new MutationObserver((e=>{e.forEach((e=>{"characterData"!==e.type&&"childList"!==e.type||e.target.firstChild&&(document.querySelector(".waline-comment-count").innerHTML=e.target.firstChild.textContent)}))})).observe(e,{attributes:!1,childList:!0,subtree:!0,characterData:!0})}),100)}</script><script>function onAsyncLoadedDocument(e,t){togglePrismTheme("dark"!==localStorage.getItem("theme")),setTimeout((()=>{loadSpecialImg()}),42),initWaline(t),copyright(),initImgZoom(),attachDownload()}function toggleWalineTheme(e){e||document.body.classList.contains("waline-theme-dark")?document.body.classList.remove("waline-theme-dark"):document.body.classList.add("waline-theme-dark")}function onThemeToggle(e){toggleWalineTheme(e),togglePrismTheme(e)}function onSidebarCollapsed(e,t,o){const n=o.classList.contains("sidebar-left"),i=document.body.classList.contains("floating-sidebars");if(onToggleCollapsedChangedToTop(),i){const t=document.querySelector("#sidebarMask"),o=document.querySelector(".sidebar-left .tree-scroll-area"),i=isMobile();e?(t&&(t.style.display="none"),n&&o&&i&&(o.style.display="none")):(t&&(t.style.display="block"),n&&o&&i&&setTimeout((()=>{o.style.display="block"}),100))}}function onToggleCollapsedChangedToTop(){if("undefined"!=typeof scrollToTopBtn){document.querySelector(".sidebar-right").classList.contains("is-collapsed")?scrollToTopBtn.classList.add("st-collapsed"):scrollToTopBtn.classList.remove("st-collapsed")}}function copyright(){let e="© "+(new Date).getFullYear()+" "+(AUTHOR||document.querySelector('meta[name="author"]')?.getAttribute("content")||VAULT_TITLE)+' <font color="#ee802f">♡</font> 由obsidian强力驱动';SHOW_RSS_FEED&&(e+='&nbsp;<a href="lib/rss.xml"><img src="https://s21.ax1x.com/2024/04/21/pkpNoSf.png" />RSS</a>');const t=document.querySelector(".markdown-preview-sizer"),o=document.createElement("div");o.id="copyright",SHOW_PAGE_FOOTER||(o.style.display="none"),o.innerHTML=e,t.appendChild(o)}function timestampToTimeString(e){e=e||null;let t=new Date(e);return t.getFullYear()+"-"+((t.getMonth()+1<10?"0"+(t.getMonth()+1):t.getMonth()+1)+"-")+((t.getDate()<10?"0"+t.getDate():t.getDate())+" ")}function togglePrismTheme(e){const t=e?"":"-dark",o=document.getElementById("prism-theme"),n="https://unpkg.com/prismjs@1.29.0/themes/prism"+t+".min.css";if(o&&o.href===n)return;const i=document.createElement("link");i.id="prism-theme",i.rel="stylesheet",i.href=n,i.onload=()=>{o&&o.remove()},document.head.appendChild(i)}function onDomReady(e){"loading"!==document.readyState?e():document.addEventListener("DOMContentLoaded",e)}function isMobileMedia(e=768){return window.matchMedia("(max-width: "+e+"px)").matches}function initImgZoom(){ImgZoom(".document-container>.markdown-preview-view>.markdown-preview-sizer > div:not(.page-meta,.mod-footer,#waline,#scrollToTop,#copyright) img")}function onSearch(){document.querySelector(".sidebar-left input[type=search]").addEventListener("input",(e=>{setTimeout((()=>setTreeCount()),42)}))}function setTreeCount(){const e=document.querySelector(".sidebar-left .file-tree").querySelectorAll(".nav-file:not(.filtered-out)").length;if(document.querySelector("#total-files"))document.querySelector("#total-files").innerHTML=e;else{const t=document.querySelector(".tree-container .tree-header"),o=document.createElement("span");o.id="total-files",o.innerHTML=e,t.appendChild(o)}document.querySelectorAll(".sidebar-left .file-tree .nav-folder:not(.filtered-out) .tree-link .nav-folder-title").forEach((e=>{const t=e.parentElement.nextElementSibling.querySelectorAll(".nav-file:not(.filtered-out)").length;e.dataset.count=t}))}function observeTreeAreaResize(){const e=document.querySelector(".webpage-container .tree-container .tree-scroll-area");new ResizeObserver((()=>{document.querySelector("#total-files").style.right=e.offsetWidth-e.clientWidth+12+"px"})).observe(e)}function onSearchIndexing(){document.querySelector(".sidebar-left input[type=search]").placeholder="zh-cn"===LANG?"正在建立全文索引...":"Full-text indexing..."}function onSearchReady(){document.querySelector(".sidebar-left input[type=search]").placeholder="Search..."}function loadSpecialImg(){document.querySelectorAll("img[src*='+']").forEach((e=>{e.setAttribute("src",URLencode(e.getAttribute("src")))}))}function attachDownload(){setTimeout((()=>{document.querySelectorAll(".internal-embed.file-embed").forEach((e=>{e.onclick=()=>{window.open(e.getAttribute("src"))}}))}),42)}function onScrollIntoViewStart(e,t,o){setTimeout((()=>{const e=document.querySelector(".document-container>.markdown-preview-view");e.scrollLeft>0&&e.scrollTo(0,e.scrollTop)}),1500)}togglePrismTheme("dark"!==localStorage.getItem("theme")),onDomReady((()=>{let e=0;const t=(o=50)=>{const n=document.querySelector(".mod-tree-file .tree-link[href='index.html'] .tree-item-title");if(!(e>6e4)){if(n&&"index"===n.innerHTML)return n.innerHTML="首页",void loadSpecialImg();e+=o,setTimeout((()=>{t(o)}),o)}};"zh-cn"===LANG&&t(),initWaline(),toggleWalineTheme("dark"!==localStorage.getItem("theme")),copyright(),document.querySelector(".document-container").classList.remove("hide");const o=setInterval((()=>{const e=document.querySelector(".nav-file.mod-active");e&&e.parentElement&&(o&&clearInterval(o),setTimeout((()=>{if(setTimeout((()=>{const e=document.querySelectorAll(".tree-container .collapse-icon");e.length>0&&void 0===e[0].style.translate&&e.forEach((e=>{e.style.left=0}))}),50),SHOW_FILE_NUMBER&&(setTreeCount(),observeTreeAreaResize(),onSearch()),FILE_COLORS&&USE_FILE_COLOR_PLUGIN&&Object.getOwnPropertyNames(FILE_COLORS).length)for(const e in FILE_COLORS){const t=document.querySelector(".sidebar-left .tree-link[data-path='"+e+"'] .tree-item-title");t&&(t.style.color=FILE_COLORS[e])}attachDownload()}),42))}),50),n=document.createElement("div");n.id="sidebarMask",n.style="position:fixed;top:0;left:0;opacity:0;z-index:9;width:100%;height:100%;display:none;",n.onclick=function(){this.style.display="none"},document.body.appendChild(n),initImgZoom(),document.querySelector(".webpage-container input[type=search]").addEventListener("input",(e=>{searchReady||EasyNotice&&EasyNotice.createNotice("zh-cn"===LANG?"正在建立全文索引，请稍后重试...":"Full-text indexing, please try again later.",1500,"left:12px;top:12px;",!0,!1)}))}))</script><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-EJ4LL9C0ZB"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-EJ4LL9C0ZB")</script></head><body class="publish css-settings-manager theme-dark native-scrollbars show-inline-title show-ribbon outliner-plugin-dnd"><script defer="">let theme=localStorage.getItem("theme")||DEFAULT_THEME||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light");"dark"==theme?(document.body.classList.add("theme-dark"),document.body.classList.remove("theme-light")):(document.body.classList.add("theme-light"),document.body.classList.remove("theme-dark")),window.innerWidth<480?document.body.classList.add("is-phone"):window.innerWidth<768?document.body.classList.add("is-tablet"):window.innerWidth<1024?document.body.classList.add("is-small-screen"):document.body.classList.add("is-large-screen")</script><div class="webpage-container workspace"><div class="sidebar-left sidebar"><div class="sidebar-handle"></div><div class="sidebar-topbar"><div class="topbar-content"><label class="theme-toggle-container" for="theme_toggle"><input class="theme-toggle-input" type="checkbox" id="theme_toggle"><div class="toggle-background"></div></label></div><div class="clickable-icon sidebar-collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><path d="M21 3H3C1.89543 3 1 3.89543 1 5V19C1 20.1046 1.89543 21 3 21H21C22.1046 21 23 20.1046 23 19V5C23 3.89543 22.1046 3 21 3Z"></path><path d="M10 4V20"></path><path d="M4 7H7"></path><path d="M4 10H7"></path><path d="M4 13H7"></path></svg></div></div><div class="sidebar-content"><div class="search-input-container"><input enterkeyhint="search" type="search" spellcheck="false" placeholder="Search..."><div class="search-input-clear-button" aria-label="Clear search"></div></div><include src="lib/html/file-tree.html?v=1.8.03&amp;t=1748680363986"></include></div><script defer="">let ls = document.querySelector(".sidebar-left"); ls.classList.add("is-collapsed"); if (window.innerWidth > 768) ls.classList.remove("is-collapsed"); ls.style.setProperty("--sidebar-width", localStorage.getItem("sidebar-left-width"));</script></div><div class="document-container markdown-reading-view hide"><div class="markdown-preview-view markdown-rendered allow-fold-headings allow-fold-lists is-readable-line-width"><style id="MJX-CHTML-styles">mjx-c.mjx-c4A::before{padding:.683em .514em .022em 0;content:"J"}mjx-c.mjx-c2229::before{padding:.598em .667em .022em 0;content:"∩"}mjx-c.mjx-c222A::before{padding:.598em .667em .022em 0;content:"∪"}mjx-c.mjx-c42::before{padding:.683em .708em 0 0;content:"B"}mjx-c.mjx-c43::before{padding:.705em .722em .021em 0;content:"C"}mjx-c.mjx-c54::before{padding:.677em .722em 0 0;content:"T"}mjx-c.mjx-c2124.TEX-A::before{padding:.683em .667em 0 0;content:"Z"}mjx-c.mjx-c25::before{padding:.75em .833em .056em 0;content:"%"}mjx-c.mjx-c2297::before{padding:.583em .778em .083em 0;content:"⊗"}mjx-c.mjx-c221A.TEX-S4::before{padding:1.75em 1.02em 1.25em 0;content:"√"}mjx-c.mjx-c1D708.TEX-I::before{padding:.442em .53em 0 0;content:"ν"}mjx-c.mjx-c76::before{padding:.431em .528em .011em 0;content:"v"}mjx-c.mjx-c1D719.TEX-I::before{padding:.694em .596em .205em 0;content:"ϕ"}mjx-c.mjx-cB1::before{padding:.666em .778em 0 0;content:"±"}mjx-c.mjx-c3A6::before{padding:.683em .722em 0 0;content:"Φ"}mjx-c.mjx-c222B.TEX-S2::before{padding:1.36em .944em .862em 0;content:"∫"}mjx-c.mjx-c220F.TEX-S2::before{padding:.95em 1.278em .45em 0;content:"∏"}mjx-c.mjx-c200B::before{padding:0;content:""}mjx-c.mjx-cD7::before{padding:.491em .778em 0 0;content:"×"}mjx-c.mjx-c1D543.TEX-A::before{padding:.683em .667em 0 0;content:"L"}mjx-c.mjx-c2190::before{padding:.511em 1em .011em 0;content:"←"}mjx-c.mjx-c1D715::before{padding:.715em .566em .022em 0;content:"∂"}mjx-c.mjx-c45.TEX-C::before{padding:.705em .564em .022em 0;content:"E"}mjx-c.mjx-c1D702.TEX-I::before{padding:.442em .497em .216em 0;content:"η"}mjx-c.mjx-c4C.TEX-C::before{padding:.705em .69em .022em 0;content:"L"}mjx-c.mjx-c1D431.TEX-B::before{padding:.444em .607em 0 0;content:"x"}mjx-c.mjx-c1D432.TEX-B::before{padding:.444em .607em .2em 0;content:"y"}mjx-c.mjx-c1D706.TEX-I::before{padding:.694em .583em .012em 0;content:"λ"}mjx-c.mjx-c2225::before{padding:.75em .5em .25em 0;content:"∥"}mjx-c.mjx-c4C::before{padding:.683em .625em 0 0;content:"L"}mjx-c.mjx-c55::before{padding:.683em .75em .022em 0;content:"U"}mjx-c.mjx-c77::before{padding:.431em .722em .011em 0;content:"w"}mjx-stretchy-v.mjx-c5B mjx-beg mjx-c::before{content:"⎡";padding:1.154em .667em .645em 0}mjx-stretchy-v.mjx-c5B mjx-ext mjx-c::before{content:"⎢";width:.667em}mjx-stretchy-v.mjx-c5B mjx-end mjx-c::before{content:"⎣";padding:1.155em .667em .644em 0}mjx-stretchy-v.mjx-c5B>mjx-end{margin-top:-1.799em}mjx-stretchy-v.mjx-c5B>mjx-ext{border-top-width:1.769em;border-bottom-width:1.769em}mjx-stretchy-v.mjx-c5D mjx-beg mjx-c::before{content:"⎤";padding:1.154em .667em .645em 0}mjx-stretchy-v.mjx-c5D mjx-ext mjx-c::before{content:"⎥";width:.667em}mjx-stretchy-v.mjx-c5D mjx-end mjx-c::before{content:"⎦";padding:1.155em .667em .644em 0}mjx-stretchy-v.mjx-c5D>mjx-end{margin-top:-1.799em}mjx-stretchy-v.mjx-c5D>mjx-ext{border-top-width:1.769em;border-bottom-width:1.769em}mjx-c.mjx-c41::before{padding:.716em .75em 0 0;content:"A"}mjx-c.mjx-c52::before{padding:.683em .736em .022em 0;content:"R"}mjx-c.mjx-c49::before{padding:.683em .361em 0 0;content:"I"}mjx-c.mjx-c50::before{padding:.683em .681em 0 0;content:"P"}mjx-c.mjx-c223C::before{padding:.367em .778em 0 0;content:"∼"}mjx-c.mjx-c55.TEX-C::before{padding:.683em .687em .028em 0;content:"U"}mjx-c.mjx-c28.TEX-S4::before{padding:1.75em .792em 1.249em 0;content:"("}mjx-c.mjx-c221A.TEX-S3::before{padding:1.45em 1.02em .95em 0;content:"√"}mjx-c.mjx-c29.TEX-S4::before{padding:1.75em .792em 1.249em 0;content:")"}mjx-c.mjx-c4E.TEX-C::before{padding:.789em .979em .05em 0;content:"N"}mjx-c.mjx-c221A.TEX-S2::before{padding:1.15em 1.02em .65em 0;content:"√"}mjx-c.mjx-c5E::before{padding:.694em .5em 0 0;content:"^"}mjx-c.mjx-c1D707.TEX-I::before{padding:.442em .603em .216em 0;content:"μ"}mjx-c.mjx-c2A02.TEX-S1::before{padding:.75em 1.111em .25em 0;content:"⨂"}mjx-c.mjx-c23::before{padding:.694em .833em .194em 0;content:"#"}mjx-c.mjx-c1D43D.TEX-I::before{padding:.683em .633em .022em 0;content:"J"}mjx-c.mjx-c1D43E.TEX-I::before{padding:.683em .889em 0 0;content:"K"}mjx-c.mjx-cAF::before{padding:.59em .5em 0 0;content:"¯"}mjx-c.mjx-c1D70B.TEX-I::before{padding:.431em .57em .011em 0;content:"π"}mjx-c.mjx-c1D70F.TEX-I::before{padding:.431em .517em .013em 0;content:"τ"}mjx-c.mjx-c1D712.TEX-I::before{padding:.442em .626em .204em 0;content:"χ"}mjx-c.mjx-c2013::before{padding:.285em .5em 0 0;content:"–"}mjx-c.mjx-c21::before{padding:.716em .278em 0 0;content:"!"}mjx-mover{display:inline-block;text-align:left}mjx-mover:not([limits=false]){padding-top:.1em}mjx-mover:not([limits=false])>*{display:block;text-align:left}mjx-c.mjx-c393::before{padding:.68em .625em 0 0;content:"Γ"}mjx-c.mjx-c50.TEX-C::before{padding:.683em .733em .057em 0;content:"P"}mjx-c.mjx-c2286::before{padding:.636em .778em .138em 0;content:"⊆"}mjx-c.mjx-c1D6FE.TEX-I::before{padding:.441em .543em .216em 0;content:"γ"}mjx-c.mjx-c1D43B.TEX-I::before{padding:.683em .888em 0 0;content:"H"}mjx-c.mjx-c1D44D.TEX-I::before{padding:.683em .723em 0 0;content:"Z"}mjx-c.mjx-c2205::before{padding:.772em .5em .078em 0;content:"∅"}mjx-c.mjx-c73::before{padding:.448em .394em .011em 0;content:"s"}mjx-c.mjx-c1D44C.TEX-I::before{padding:.683em .763em 0 0;content:"Y"}mjx-c.mjx-c1D6FC.TEX-I::before{padding:.442em .64em .011em 0;content:"α"}mjx-c.mjx-c1D700.TEX-I::before{padding:.452em .466em .022em 0;content:"ε"}mjx-c.mjx-c1D6FD.TEX-I::before{padding:.705em .566em .194em 0;content:"β"}mjx-c.mjx-c3A3::before{padding:.683em .722em 0 0;content:"Σ"}mjx-c.mjx-c1D444.TEX-I::before{padding:.704em .791em .194em 0;content:"Q"}mjx-c.mjx-c1D6FF.TEX-I::before{padding:.717em .444em .01em 0;content:"δ"}.mjx-stretched mjx-c.mjx-c2013::before{content:"–"}mjx-stretchy-h.mjx-c2013 mjx-ext mjx-c::before{content:"–";padding:.285em 0 0}mjx-c.mjx-c1D70E.TEX-I::before{padding:.431em .571em .011em 0;content:"σ"}mjx-c.mjx-c2227::before{padding:.598em .667em .022em 0;content:"∧"}mjx-c.mjx-c1D716.TEX-I::before{padding:.431em .406em .011em 0;content:"ϵ"}mjx-c.mjx-c2033::before{padding:.56em .55em 0 0;content:"′′"}mjx-c.mjx-c1D44B.TEX-I::before{padding:.683em .852em 0 0;content:"X"}mjx-c.mjx-c2287::before{padding:.636em .778em .138em 0;content:"⊇"}mjx-c.mjx-c2F::before{padding:.75em .5em .25em 0;content:"/"}mjx-c.mjx-c22EF::before{padding:.31em 1.172em 0 0;content:"⋯"}mjx-c.mjx-c3B::before{padding:.43em .278em .194em 0;content:";"}mjx-c.mjx-c1D43C.TEX-I::before{padding:.683em .504em 0 0;content:"I"}mjx-c.mjx-c5F::before{padding:0 .5em .062em 0;content:"_"}mjx-c.mjx-c2218::before{padding:.444em .5em 0 0;content:"∘"}mjx-c.mjx-c75::before{padding:.442em .556em .011em 0;content:"u"}mjx-c.mjx-c2026::before{padding:.12em 1.172em 0 0;content:"…"}mjx-stretchy-v.mjx-c7B mjx-beg mjx-c::before{content:"⎧";padding:.899em .889em .01em 0}mjx-stretchy-v.mjx-c7B mjx-ext mjx-c::before{content:"⎪";width:.889em}mjx-stretchy-v.mjx-c7B mjx-end mjx-c::before{content:"⎩";padding:.01em .889em .899em 0}mjx-stretchy-v.mjx-c7B mjx-mid mjx-c::before{content:"⎨";padding:1.16em .889em .66em 0}mjx-stretchy-v.mjx-c7B>mjx-mid{margin-top:-.91em;margin-bottom:-.91em}mjx-stretchy-v.mjx-c7B>mjx-end{margin-top:-.909em}mjx-stretchy-v.mjx-c7B>mjx-ext{height:50%;border-top-width:.879em;border-bottom-width:.879em}mjx-c.mjx-c2032::before{padding:.56em .275em 0 0;content:"′"}mjx-c.mjx-c26::before{padding:.716em .778em .022em 0;content:"&"}mjx-msqrt{display:inline-block;text-align:left}mjx-root{display:inline-block;white-space:nowrap}mjx-surd{display:inline-block;vertical-align:top}mjx-sqrt{display:inline-block;padding-top:.07em}mjx-sqrt>mjx-box{border-top:.07em solid}mjx-sqrt.mjx-tall>mjx-box{padding-left:.3em;margin-left:-.3em}mjx-c.mjx-c3A9::before{padding:.704em .722em 0 0;content:"Ω"}mjx-c.mjx-c221A::before{padding:.8em .853em .2em 0;content:"√"}mjx-c.mjx-c2192::before{padding:.511em 1em .011em 0;content:"→"}mjx-c.mjx-c230A.TEX-S2::before{padding:1.15em .528em .649em 0;content:"⌊"}mjx-c.mjx-c53::before{padding:.705em .556em .022em 0;content:"S"}mjx-c.mjx-c7A::before{padding:.431em .444em 0 0;content:"z"}mjx-c.mjx-c65::before{padding:.448em .444em .011em 0;content:"e"}mjx-c.mjx-c20::before{padding:0 .25em 0 0;content:" "}mjx-c.mjx-c6E::before{padding:.442em .556em 0 0;content:"n"}mjx-c.mjx-c62::before{padding:.694em .556em .011em 0;content:"b"}mjx-c.mjx-c63::before{padding:.448em .444em .011em 0;content:"c"}mjx-c.mjx-c6B::before{padding:.694em .528em 0 0;content:"k"}mjx-c.mjx-c68::before{padding:.694em .556em 0 0;content:"h"}mjx-c.mjx-c70::before{padding:.442em .556em .194em 0;content:"p"}mjx-c.mjx-c79::before{padding:.431em .528em .204em 0;content:"y"}mjx-c.mjx-c72::before{padding:.442em .392em 0 0;content:"r"}mjx-c.mjx-c64::before{padding:.694em .556em .011em 0;content:"d"}mjx-c.mjx-c230B.TEX-S2::before{padding:1.15em .528em .649em 0;content:"⌋"}mjx-c.mjx-c230A.TEX-S1::before{padding:.85em .472em .349em 0;content:"⌊"}mjx-c.mjx-c230B.TEX-S1::before{padding:.85em .472em .349em 0;content:"⌋"}mjx-c.mjx-c74::before{padding:.615em .389em .01em 0;content:"t"}mjx-c.mjx-c1D44A.TEX-I::before{padding:.683em 1.048em .022em 0;content:"W"}mjx-c.mjx-c2235.TEX-A::before{padding:.471em .667em .082em 0;content:"∵"}mjx-c.mjx-c1D435.TEX-I::before{padding:.683em .759em 0 0;content:"B"}mjx-c.mjx-c36::before{padding:.666em .5em .022em 0;content:"6"}mjx-c.mjx-c37::before{padding:.676em .5em .022em 0;content:"7"}mjx-c.mjx-c38::before{padding:.666em .5em .022em 0;content:"8"}mjx-c.mjx-c2308::before{padding:.75em .444em .25em 0;content:"⌈"}mjx-c.mjx-c2309::before{padding:.75em .444em .25em 0;content:"⌉"}mjx-c.mjx-c2234.TEX-A::before{padding:.471em .667em .082em 0;content:"∴"}mjx-c.mjx-c28.TEX-S2::before{padding:1.15em .597em .649em 0;content:"("}mjx-c.mjx-c29.TEX-S2::before{padding:1.15em .597em .649em 0;content:")"}mjx-c.mjx-c28.TEX-S3::before{padding:1.45em .736em .949em 0;content:"("}mjx-c.mjx-c29.TEX-S3::before{padding:1.45em .736em .949em 0;content:")"}mjx-c.mjx-c394::before{padding:.716em .833em 0 0;content:"Δ"}mjx-c.mjx-c221E::before{padding:.442em 1em .011em 0;content:"∞"}mjx-c.mjx-c2248::before{padding:.483em .778em 0 0;content:"≈"}mjx-c.mjx-c6D::before{padding:.442em .833em 0 0;content:"m"}mjx-c.mjx-c61::before{padding:.448em .5em .011em 0;content:"a"}mjx-c.mjx-c78::before{padding:.431em .528em 0 0;content:"x"}mjx-c.mjx-c1D45E.TEX-I::before{padding:.442em .46em .194em 0;content:"q"}mjx-c.mjx-c34::before{padding:.677em .5em 0 0;content:"4"}mjx-c.mjx-c3A::before{padding:.43em .278em 0 0;content:":"}mjx-c.mjx-c1D703.TEX-I::before{padding:.705em .469em .01em 0;content:"θ"}mjx-c.mjx-c2200::before{padding:.694em .556em .022em 0;content:"∀"}mjx-c.mjx-c2032::before{padding:.56em .275em 0 0;content:"′"}mjx-c.mjx-c1D445.TEX-I::before{padding:.683em .759em .021em 0;content:"R"}mjx-c.mjx-c2211.TEX-S1::before{padding:.75em 1.056em .25em 0;content:"∑"}mjx-c.mjx-c2033::before{padding:.56em .55em 0 0;content:"′′"}mjx-c.mjx-c1D458.TEX-I::before{padding:.694em .521em .011em 0;content:"k"}mjx-munder{display:inline-block;text-align:left}mjx-over{text-align:left}mjx-munder:not([limits=false]){display:inline-table}mjx-munder>mjx-row{text-align:left}mjx-under{padding-bottom:.1em}mjx-c.mjx-c1D43A.TEX-I::before{padding:.705em .786em .022em 0;content:"G"}mjx-c.mjx-c1D449.TEX-I::before{padding:.683em .769em .022em 0;content:"V"}mjx-c.mjx-c1D438.TEX-I::before{padding:.68em .764em 0 0;content:"E"}mjx-c.mjx-c2208::before{padding:.54em .667em .04em 0;content:"∈"}mjx-c.mjx-c7B::before{padding:.75em .5em .25em 0;content:"{"}mjx-c.mjx-c39::before{padding:.666em .5em .022em 0;content:"9"}mjx-c.mjx-c7D::before{padding:.75em .5em .25em 0;content:"}"}mjx-c.mjx-c1D463.TEX-I::before{padding:.443em .485em .011em 0;content:"v"}mjx-c.mjx-c7C::before{padding:.75em .278em .249em 0;content:"|"}mjx-c.mjx-c1D434.TEX-I::before{padding:.716em .75em 0 0;content:"A"}mjx-c.mjx-cD7::before{padding:.491em .778em 0 0;content:"×"}mjx-c.mjx-c1D453.TEX-I::before{padding:.705em .55em .205em 0;content:"f"}mjx-c.mjx-c1D439.TEX-I::before{padding:.68em .749em 0 0;content:"F"}mjx-c.mjx-c2260::before{padding:.716em .778em .215em 0;content:"≠"}mjx-c.mjx-c1D448.TEX-I::before{padding:.683em .767em .022em 0;content:"U"}mjx-c.mjx-c1D437.TEX-I::before{padding:.683em .828em 0 0;content:"D"}mjx-c.mjx-c1D446.TEX-I::before{padding:.705em .645em .022em 0;content:"S"}mjx-c.mjx-c21D2::before{padding:.525em 1em .024em 0;content:"⇒"}mjx-mrow{display:inline-block;text-align:left}mjx-mtable{display:inline-block;text-align:center;vertical-align:.25em;position:relative;box-sizing:border-box;border-spacing:0px;border-collapse:collapse}mjx-mstyle[size="s"] mjx-mtable{vertical-align:.354em}mjx-labels{position:absolute;left:0;top:0}mjx-table{display:inline-block;vertical-align:-.5ex;box-sizing:border-box}mjx-table>mjx-itable{vertical-align:middle;text-align:left;box-sizing:border-box}mjx-labels>mjx-itable{position:absolute;top:0}mjx-mtable[justify=left]{text-align:left}mjx-mtable[justify=right]{text-align:right}mjx-mtable[justify=left][side=left]{padding-right:0!important}mjx-mtable[justify=left][side=right]{padding-left:0!important}mjx-mtable[justify=right][side=left]{padding-right:0!important}mjx-mtable[justify=right][side=right]{padding-left:0!important}mjx-mtable[align]{vertical-align:baseline}mjx-mtable[align=top]>mjx-table{vertical-align:top}mjx-mtable[align=bottom]>mjx-table{vertical-align:bottom}mjx-mtable[side=right] mjx-labels{min-width:100%}mjx-mtr{display:table-row;text-align:left}mjx-mtr[rowalign=top]>mjx-mtd{vertical-align:top}mjx-mtr[rowalign=center]>mjx-mtd{vertical-align:middle}mjx-mtr[rowalign=bottom]>mjx-mtd{vertical-align:bottom}mjx-mtr[rowalign=baseline]>mjx-mtd{vertical-align:baseline}mjx-mtr[rowalign=axis]>mjx-mtd{vertical-align:.25em}mjx-mtd{display:table-cell;text-align:center;padding:.215em .4em}mjx-mtd:first-child{padding-left:0}mjx-mtd:last-child{padding-right:0}mjx-mtable>*>mjx-itable>:first-child>mjx-mtd{padding-top:0}mjx-mtable>*>mjx-itable>:last-child>mjx-mtd{padding-bottom:0}mjx-tstrut{display:inline-block;height:1em;vertical-align:-.25em}mjx-labels[align=left]>mjx-mtr>mjx-mtd{text-align:left}mjx-labels[align=right]>mjx-mtr>mjx-mtd{text-align:right}mjx-mtd[extra]{padding:0}mjx-mtd[rowalign=top]{vertical-align:top}mjx-mtd[rowalign=center]{vertical-align:middle}mjx-mtd[rowalign=bottom]{vertical-align:bottom}mjx-mtd[rowalign=baseline]{vertical-align:baseline}mjx-mtd[rowalign=axis]{vertical-align:.25em}mjx-texatom{display:inline-block;text-align:left}mjx-mfrac{display:inline-block;text-align:left}mjx-frac{display:inline-block;vertical-align:.17em;padding:0 .22em}mjx-frac[type="d"]{vertical-align:.04em}mjx-frac[delims]{padding:0 .1em}mjx-frac[atop]{padding:0 .12em}mjx-frac[atop][delims]{padding:0}mjx-dtable{display:inline-table;width:100%}mjx-dtable>*{font-size:2000%}mjx-dbox{display:block;font-size:5%}mjx-num{display:block;text-align:center}mjx-den{display:block;text-align:center}mjx-mfrac[bevelled]>mjx-num{display:inline-block}mjx-mfrac[bevelled]>mjx-den{display:inline-block}mjx-den[align=right],mjx-num[align=right]{text-align:right}mjx-den[align=left],mjx-num[align=left]{text-align:left}mjx-nstrut{display:inline-block;height:.054em;width:0;vertical-align:-.054em}mjx-nstrut[type="d"]{height:.217em;vertical-align:-.217em}mjx-dstrut{display:inline-block;height:.505em;width:0}mjx-dstrut[type="d"]{height:.726em}mjx-line{display:block;box-sizing:border-box;min-height:1px;height:.06em;border-top:.06em solid;margin:.06em -.1em;overflow:hidden}mjx-line[type="d"]{margin:.18em -.1em}mjx-mspace{display:inline-block;text-align:left}mjx-munderover{display:inline-block;text-align:left}mjx-munderover:not([limits=false]){padding-top:.1em}mjx-munderover:not([limits=false])>*{display:block}mjx-msubsup{display:inline-block;text-align:left}mjx-script{display:inline-block;padding-right:.05em;padding-left:.033em}mjx-script>mjx-spacer{display:block}mjx-c.mjx-c1D442.TEX-I::before{padding:.704em .763em .022em 0;content:"O"}mjx-c.mjx-c1D447.TEX-I::before{padding:.677em .704em 0 0;content:"T"}mjx-c.mjx-c7B.TEX-S3::before{padding:1.45em .75em .949em 0;content:"{"}mjx-c.mjx-c24::before{padding:.75em .5em .056em 0;content:"$"}mjx-c.mjx-c69::before{padding:.669em .278em 0 0;content:"i"}mjx-c.mjx-c66::before{padding:.705em .372em 0 0;content:"f"}mjx-c.mjx-c2217::before{padding:.465em .5em 0 0;content:"∗"}mjx-c.mjx-c1D450.TEX-I::before{padding:.442em .433em .011em 0;content:"c"}mjx-c.mjx-c2211.TEX-S2::before{padding:.95em 1.444em .45em 0;content:"∑"}mjx-c.mjx-c28.TEX-S1::before{padding:.85em .458em .349em 0;content:"("}mjx-c.mjx-c29.TEX-S1::before{padding:.85em .458em .349em 0;content:")"}mjx-c.mjx-c5B.TEX-S1::before{padding:.85em .417em .349em 0;content:"["}mjx-c.mjx-c5D.TEX-S1::before{padding:.85em .417em .349em 0;content:"]"}mjx-c.mjx-c1D43F.TEX-I::before{padding:.683em .681em 0 0;content:"L"}mjx-c.mjx-c6C::before{padding:.694em .278em 0 0;content:"l"}mjx-c.mjx-c6F::before{padding:.448em .5em .01em 0;content:"o"}mjx-c.mjx-c67::before{padding:.453em .5em .206em 0;content:"g"}mjx-c.mjx-c2061::before{padding:0;content:""}mjx-c.mjx-c22C5::before{padding:.31em .278em 0 0;content:"⋅"}mjx-c.mjx-c5B::before{padding:.75em .278em .25em 0;content:"["}mjx-c.mjx-c5D::before{padding:.75em .278em .25em 0;content:"]"}mjx-c.mjx-c230A::before{padding:.75em .444em .25em 0;content:"⌊"}mjx-c.mjx-c230B::before{padding:.75em .444em .25em 0;content:"⌋"}mjx-msub{display:inline-block;text-align:left}mjx-c.mjx-c1D466.TEX-I::before{padding:.442em .49em .205em 0;content:"y"}mjx-c.mjx-c1D467.TEX-I::before{padding:.442em .465em .011em 0;content:"z"}mjx-c.mjx-c2C::before{padding:.121em .278em .194em 0;content:","}mjx-c.mjx-c1D45A.TEX-I::before{padding:.442em .878em .011em 0;content:"m"}mjx-c.mjx-c1D45D.TEX-I::before{padding:.442em .503em .194em 0;content:"p"}mjx-c.mjx-c35::before{padding:.666em .5em .022em 0;content:"5"}mjx-c.mjx-c1D440.TEX-I::before{padding:.683em 1.051em 0 0;content:"M"}mjx-c.mjx-c1D457.TEX-I::before{padding:.661em .412em .204em 0;content:"j"}mjx-c.mjx-c1D441.TEX-I::before{padding:.683em .888em 0 0;content:"N"}mjx-c.mjx-c1D443.TEX-I::before{padding:.683em .751em 0 0;content:"P"}mjx-c.mjx-c1D44E.TEX-I::before{padding:.441em .529em .01em 0;content:"a"}mjx-c.mjx-c1D460.TEX-I::before{padding:.442em .469em .01em 0;content:"s"}mjx-c.mjx-c2E::before{padding:.12em .278em 0 0;content:"."}mjx-c.mjx-c1D454.TEX-I::before{padding:.442em .477em .205em 0;content:"g"}mjx-c.mjx-c210E.TEX-I::before{padding:.694em .576em .011em 0;content:"h"}mjx-c.mjx-c3D::before{padding:.583em .778em .082em 0;content:"="}mjx-mo{display:inline-block;text-align:left}mjx-stretchy-h{display:inline-table;width:100%}mjx-stretchy-h>*{display:table-cell;width:0}mjx-stretchy-h>*>mjx-c{display:inline-block;transform:scaleX(1)}mjx-stretchy-h>*>mjx-c::before{display:inline-block;width:initial}mjx-stretchy-h>mjx-ext{overflow:clip visible;width:100%}mjx-stretchy-h>mjx-ext>mjx-c::before{transform:scaleX(500)}mjx-stretchy-h>mjx-ext>mjx-c{width:0}mjx-stretchy-h>mjx-beg>mjx-c{margin-right:-.1em}mjx-stretchy-h>mjx-end>mjx-c{margin-left:-.1em}mjx-stretchy-v{display:inline-block}mjx-stretchy-v>*{display:block}mjx-stretchy-v>mjx-beg{height:0}mjx-stretchy-v>mjx-end>mjx-c{display:block}mjx-stretchy-v>*>mjx-c{transform:scaleY(1);transform-origin:left center;overflow:hidden}mjx-stretchy-v>mjx-ext{display:block;height:100%;box-sizing:border-box;border:0 solid transparent;overflow:visible clip}mjx-stretchy-v>mjx-ext>mjx-c::before{width:initial;box-sizing:border-box}mjx-stretchy-v>mjx-ext>mjx-c{transform:scaleY(500) translateY(.075em);overflow:visible}mjx-mark{display:inline-block;height:0}mjx-c.mjx-c2265::before{padding:.636em .778em .138em 0;content:"≥"}mjx-c.mjx-c1D459.TEX-I::before{padding:.694em .298em .011em 0;content:"l"}mjx-c.mjx-c1D464.TEX-I::before{padding:.443em .716em .011em 0;content:"w"}mjx-c.mjx-c1D45F.TEX-I::before{padding:.442em .451em .011em 0;content:"r"}mjx-c.mjx-c1D44F.TEX-I::before{padding:.694em .429em .011em 0;content:"b"}mjx-c.mjx-c1D451.TEX-I::before{padding:.694em .52em .01em 0;content:"d"}mjx-c.mjx-c3E::before{padding:.54em .778em .04em 0;content:">"}mjx-c.mjx-c28::before{padding:.75em .389em .25em 0;content:"("}mjx-c.mjx-c1D465.TEX-I::before{padding:.442em .572em .011em 0;content:"x"}mjx-c.mjx-c2B::before{padding:.583em .778em .082em 0;content:"+"}mjx-c.mjx-c29::before{padding:.75em .389em .25em 0;content:")"}mjx-c.mjx-c3C::before{padding:.54em .778em .04em 0;content:"<"}mjx-c.mjx-c2212::before{padding:.583em .778em .082em 0;content:"−"}mjx-c.mjx-c2264::before{padding:.636em .778em .138em 0;content:"≤"}mjx-container[jax=CHTML]{line-height:0}mjx-container [space="1"]{margin-left:.111em}mjx-container [space="2"]{margin-left:.167em}mjx-container [space="3"]{margin-left:.222em}mjx-container [space="4"]{margin-left:.278em}mjx-container [space="5"]{margin-left:.333em}mjx-container [rspace="1"]{margin-right:.111em}mjx-container [rspace="2"]{margin-right:.167em}mjx-container [rspace="3"]{margin-right:.222em}mjx-container [rspace="4"]{margin-right:.278em}mjx-container [rspace="5"]{margin-right:.333em}mjx-container [size="s"]{font-size:70.7%}mjx-container [size=ss]{font-size:50%}mjx-container [size=Tn]{font-size:60%}mjx-container [size=sm]{font-size:85%}mjx-container [size=lg]{font-size:120%}mjx-container [size=Lg]{font-size:144%}mjx-container [size=LG]{font-size:173%}mjx-container [size=hg]{font-size:207%}mjx-container [size=HG]{font-size:249%}mjx-container [width=full]{width:100%}mjx-box{display:inline-block}mjx-block{display:block}mjx-itable{display:inline-table}mjx-row{display:table-row}mjx-row>*{display:table-cell}mjx-mtext{display:inline-block;text-align:left}mjx-mstyle{display:inline-block}mjx-merror{display:inline-block;color:red;background-color:#ff0}mjx-mphantom{visibility:hidden}mjx-assistive-mml{top:0;left:0;clip:rect(1px,1px,1px,1px);user-select:none;position:absolute!important;padding:1px 0 0!important;border:0!important;display:block!important;width:auto!important;overflow:hidden!important}mjx-assistive-mml[display=block]{width:100%!important}mjx-math{display:inline-block;text-align:left;line-height:0;text-indent:0;font-style:normal;font-weight:400;font-size:100%;font-size-adjust:none;letter-spacing:normal;border-collapse:collapse;overflow-wrap:normal;word-spacing:normal;white-space:nowrap;direction:ltr;padding:1px 0}mjx-container[jax=CHTML][display=true]{display:block;text-align:center;margin:1em 0}mjx-container[jax=CHTML][display=true][width=full]{display:flex}mjx-container[jax=CHTML][display=true] mjx-math{padding:0}mjx-container[jax=CHTML][justify=left]{text-align:left}mjx-container[jax=CHTML][justify=right]{text-align:right}mjx-msup{display:inline-block;text-align:left}mjx-mi{display:inline-block;text-align:left}mjx-c{display:inline-block}mjx-utext{display:inline-block;padding:.75em 0 .2em}mjx-mn{display:inline-block;text-align:left}mjx-c::before{display:block;width:0}.MJX-TEX{font-family:MJXZERO,MJXTEX}.TEX-B{font-family:MJXZERO,MJXTEX-B}.TEX-I{font-family:MJXZERO,MJXTEX-I}.TEX-MI{font-family:MJXZERO,MJXTEX-MI}.TEX-BI{font-family:MJXZERO,MJXTEX-BI}.TEX-S1{font-family:MJXZERO,MJXTEX-S1}.TEX-S2{font-family:MJXZERO,MJXTEX-S2}.TEX-S3{font-family:MJXZERO,MJXTEX-S3}.TEX-S4{font-family:MJXZERO,MJXTEX-S4}.TEX-A{font-family:MJXZERO,MJXTEX-A}.TEX-C{font-family:MJXZERO,MJXTEX-C}.TEX-CB{font-family:MJXZERO,MJXTEX-CB}.TEX-FR{font-family:MJXZERO,MJXTEX-FR}.TEX-FRB{font-family:MJXZERO,MJXTEX-FRB}.TEX-SS{font-family:MJXZERO,MJXTEX-SS}.TEX-SSB{font-family:MJXZERO,MJXTEX-SSB}.TEX-SSI{font-family:MJXZERO,MJXTEX-SSI}.TEX-SC{font-family:MJXZERO,MJXTEX-SC}.TEX-T{font-family:MJXZERO,MJXTEX-T}.TEX-V{font-family:MJXZERO,MJXTEX-V}.TEX-VB{font-family:MJXZERO,MJXTEX-VB}mjx-stretchy-h mjx-c,mjx-stretchy-v mjx-c{font-family:MJXZERO,MJXTEX-S1,MJXTEX-S4,MJXTEX,MJXTEX-A!important}@font-face{font-family:MJXZERO;src:url("lib/fonts/mathjax_zero.woff") format("woff")}@font-face{font-family:MJXTEX;src:url("lib/fonts/mathjax_main-regular.woff") format("woff")}@font-face{font-family:MJXTEX-B;src:url("lib/fonts/mathjax_main-bold.woff") format("woff")}@font-face{font-family:MJXTEX-I;src:url("lib/fonts/mathjax_math-italic.woff") format("woff")}@font-face{font-family:MJXTEX-MI;src:url("lib/fonts/mathjax_main-italic.woff") format("woff")}@font-face{font-family:MJXTEX-BI;src:url("lib/fonts/mathjax_math-bolditalic.woff") format("woff")}@font-face{font-family:MJXTEX-S1;src:url("lib/fonts/mathjax_size1-regular.woff") format("woff")}@font-face{font-family:MJXTEX-S2;src:url("lib/fonts/mathjax_size2-regular.woff") format("woff")}@font-face{font-family:MJXTEX-S3;src:url("lib/fonts/mathjax_size3-regular.woff") format("woff")}@font-face{font-family:MJXTEX-S4;src:url("lib/fonts/mathjax_size4-regular.woff") format("woff")}@font-face{font-family:MJXTEX-A;src:url("lib/fonts/mathjax_ams-regular.woff") format("woff")}@font-face{font-family:MJXTEX-C;src:url("lib/fonts/mathjax_calligraphic-regular.woff") format("woff")}@font-face{font-family:MJXTEX-CB;src:url("lib/fonts/mathjax_calligraphic-bold.woff") format("woff")}@font-face{font-family:MJXTEX-FR;src:url("lib/fonts/mathjax_fraktur-regular.woff") format("woff")}@font-face{font-family:MJXTEX-FRB;src:url("lib/fonts/mathjax_fraktur-bold.woff") format("woff")}@font-face{font-family:MJXTEX-SS;src:url("lib/fonts/mathjax_sansserif-regular.woff") format("woff")}@font-face{font-family:MJXTEX-SSB;src:url("lib/fonts/mathjax_sansserif-bold.woff") format("woff")}@font-face{font-family:MJXTEX-SSI;src:url("lib/fonts/mathjax_sansserif-italic.woff") format("woff")}@font-face{font-family:MJXTEX-SC;src:url("lib/fonts/mathjax_script-regular.woff") format("woff")}@font-face{font-family:MJXTEX-T;src:url("lib/fonts/mathjax_typewriter-regular.woff") format("woff")}@font-face{font-family:MJXTEX-V;src:url("lib/fonts/mathjax_vector-regular.woff") format("woff")}@font-face{font-family:MJXTEX-VB;src:url("lib/fonts/mathjax_vector-bold.woff") format("woff")}mjx-c.mjx-c1D436.TEX-I::before{padding:.705em .76em .022em 0;content:"C"}mjx-c.mjx-c30::before{padding:.666em .5em .022em 0;content:"0"}mjx-c.mjx-cA0::before{padding:0 .25em 0 0;content:" "}mjx-c.mjx-c1D45C.TEX-I::before{padding:.441em .485em .011em 0;content:"o"}mjx-c.mjx-c1D45B.TEX-I::before{padding:.442em .6em .011em 0;content:"n"}mjx-c.mjx-c1D461.TEX-I::before{padding:.626em .361em .011em 0;content:"t"}mjx-c.mjx-c1D456.TEX-I::before{padding:.661em .345em .011em 0;content:"i"}mjx-c.mjx-c1D462.TEX-I::before{padding:.442em .572em .011em 0;content:"u"}mjx-c.mjx-c1D452.TEX-I::before{padding:.442em .466em .011em 0;content:"e"}mjx-c.mjx-c31::before{padding:.666em .5em 0 0;content:"1"}mjx-c.mjx-c32::before{padding:.666em .5em 0 0;content:"2"}mjx-c.mjx-c33::before{padding:.665em .5em .022em 0;content:"3"}</style><pre class="frontmatter language-yaml" tabindex="0" style="display: none;"><code class="language-yaml is-loaded"><span class="token key atrule">date</span><span class="token punctuation">:</span> <span class="token datetime number">2024-12-13</span>
<span class="token key atrule">title</span><span class="token punctuation">:</span> BDA<span class="token punctuation">-</span>Project<span class="token punctuation">-</span>Report
<span class="token key atrule">status</span><span class="token punctuation">:</span> DONE
<span class="token key atrule">author</span><span class="token punctuation">:</span>
  <span class="token punctuation">-</span> AllenYGY
<span class="token key atrule">tags</span><span class="token punctuation">:</span>
  <span class="token punctuation">-</span> Project
  <span class="token punctuation">-</span> Report
  <span class="token punctuation">-</span> BDA
<span class="token key atrule">publish</span><span class="token punctuation">:</span> <span class="token boolean important">True</span></code><button class="copy-code-button"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-copy"><rect x="8" y="8" width="14" height="14" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></pre><div class="markdown-preview-sizer markdown-preview-section"><h1 class="page-title heading inline-title" id="BDA-Project-Report"><p dir="auto">BDA-Project-Report</p></h1><div class="el-h1 heading-wrapper"><div class="heading-children"><div class="el-h2 heading-wrapper"><h2 data-heading="Abstract" dir="auto" class="heading" id="Abstract"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>Abstract</h2><div class="heading-children"><div class="el-p"><p dir="auto">Text classification is the bedrock of natural language processing (NLP) activities, like content moderation, spam detection, and sentiment analysis. This report focuses on an innovative, well-designed system for identifying illegal texts and filtering high-quality comments, which combines traditional machine learning (ML) methods and novel deep learning (DL) techniques to attain the best performance. The illegal text detection module incorporates sparse rule-based sensitive word filtering in addition to FastText's rapid filtering and BERT for final classification, ending with a balance between processing power and accuracy. Subjects used as experimental subjects indicate that the deep learning methods, such as BERT and FastText, excel in comparison with traditional ML models, which are Multinomial Naive Bayes, Random Forest, and XGBoost, which give almost perfect accuracy and F1-scores. The operating principles of the high-quality comment filtering part are the utilization of a pretrained BERT model to get token embeddings and the trained Auto-Encoder for the reconstruction-based quality assessment. Evaluation is done at a standard of reconstruction errors to differentiate high-quality comments, and this is through a threshold-based method that gives reliable filtering. The experimental analysis focuses on the model's two-stage hybrid procedure for illegal text detection and concludes that the Auto-Encoder captures the content features for which it was trained properly.</p></div></div></div><div class="el-h2 heading-wrapper"><h2 data-heading="Introduction" dir="auto" class="heading" id="Introduction"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>Introduction</h2><div class="heading-children"><div class="el-p"><p dir="auto">As digital platforms are expanding rapidly, the supervision of quality and legality of user content on them is one of the problems that needs immediate attention. Text classification, as one of the core features of natural language processing (NLP), is one of the most important solutions to this challenge. The use of text classification in applications like spam detection, sentiment analysis, and content moderation has a considerable reliance on its precision and speed. On the contrary, textual data's heterogenic nature, context variation, and semantic complexity are the major issues faced by conventional machine learning (ML) techniques.</p></div><div class="el-p"><p dir="auto">Since traditional ML techniques require significant feature engineering to process text, some of the methods used are Multinomial Naive Bayes (MNB), Support Vector Machines (SVMs), and ensemble methods like Random Forest and XGBoost. Unlike these models, which perform their best with smaller datasets and comparatively simple tasks, they cannot cope with the deep semantic and contextual dependency that complex text data has.</p></div><div class="el-p"><p dir="auto">On the contrary, DL approaches, in particular, such as FastText, Recurrent Neural Networks (RNNs), Long Short-Term Memory (LSTM), the Transformer architecture, and BERT, which have introduced a leap over the original text classification methods. These models avoid the manual feature construction process and leverage word embeddings and attention mechanisms to adaptively learn context-sensitive models of text. Among these, BERT has shown the best performance by incorporating context preservation, alongside RNNs.</p></div><div class="el-p"><p dir="auto">In this report, we propose a comprehensive system designed for two primary tasks: <strong>illegal text detection</strong> and <strong>high-quality comment filtering</strong>. The system employs a <strong>hybrid approach</strong> that combines rule-based methods, lightweight DL models (FastText), and robust transformer-based models (BERT). Specifically:</p></div><div class="el-ol"><ol>
<li data-line="0" dir="auto">
<p><strong>Illegal Text Detection</strong>: A two-stage process that uses <strong>FastText</strong> for fast inference and <strong>BERT</strong> for precise classification. This approach balances computational efficiency and accuracy while handling large-scale text data.</p>
</li>
<li data-line="2" dir="auto">
<p><strong>High-Quality Comment Filtering</strong>: The system uses <strong>BERT embeddings</strong> and an <strong>Auto-Encoder</strong> to assess reconstruction errors and distinguish high-quality comments from low-quality ones.</p>
</li>
</ol></div><div class="el-p"><p dir="auto">The experimental evaluation compares traditional ML methods with DL techniques. Results show that DL models, particularly <strong>FastText</strong> and <strong>BERT</strong>, significantly outperform ML models in accuracy, precision, recall, and F1-score. The proposed Auto-Encoder further ensures effective filtering of high-quality comments based on reconstruction error thresholds.</p></div><div class="el-p"><p dir="auto">This report is structured as follows:</p></div><div class="el-ul"><ul>
<li data-line="0" dir="auto">Section 2 discusses related works and existing text classification techniques.</li>
<li data-line="1" dir="auto">Section 3 details the methodology for illegal text detection and high-quality comment filtering.</li>
<li data-line="2" dir="auto">Section 4 presents the experimental results and analysis.</li>
<li data-line="3" dir="auto">Section 5 outlines future work and concludes the report.</li>
</ul></div><div class="el-p"><p dir="auto">By integrating advanced deep learning methods with a hybrid filtering pipeline, the proposed system demonstrates its potential for scalable, efficient, and accurate text moderation in real-world applications.</p></div></div></div><div class="el-h2 heading-wrapper"><h2 data-heading="Related works" dir="auto" class="heading" id="Related_works"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>Related works</h2><div class="heading-children"><div class="el-p"><p dir="auto">Text classification has been a pivotal task in natural language processing (NLP) and has seen substantial progress over the years. The methodologies for text classification can be categorized into two primary paradigms: traditional Machine Learning (ML) approaches and Deep Learning (DL) techniques. Each of these paradigms has evolved to address various challenges posed by textual data, such as high dimensionality, context dependency, and variability in text length and semantics.</p></div><div class="el-h3 heading-wrapper"><h3 data-heading="Machine Learning Methods" dir="auto" class="heading" id="Machine_Learning_Methods"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>Machine Learning Methods</h3><div class="heading-children"><div class="el-p"><p dir="auto">Traditional ML approaches usually rely on strongly featured engineering and statistical strategies. In this context, Multinomial Naive Bayes (MNB) is probably one of the first and simplest processing techniques. MNB is a theorem of Bayes that processes with conditional independence of the features or attributes given the class label or the class category. Even if this assumption mostly doesn't hold for large data sets of the real-world case, MNB's operational efficiency and great usefulness for tasks like spam filtering and sentiment analysis on small data sets have made it popular among users. These drawbacks, however, stem from the model's inability to take into account the feature interdependence.</p></div><div class="el-p"><p dir="auto">Support Vector Machines (SVMs) are the other key latest development of conventional ML for text classification. The main feature of SVMs is the ability to identify a hyperplane that separates the data with the greatest margin, which is known as a large margin classifier, based on the dimensionality of the feature space. Through kernel tricks, SVMs get the upper hand in case of non-linear decision boundaries, thus they can be used with text data having drastic multi-patterns. SVMs have the advantage when it comes to the models produced by combining features represented by TF-IDF, for instance, in the domain of document categorization and sentiment analysis. Nevertheless, their large computational cost and too much parameter tuning make it impossible to work with large-scale datasets.</p></div><div class="el-p"><p dir="auto">Finally, the Random Forest method, as well as XGBoost and boosting methods such as LightGBM, can perform well as well in text classification. The Random Forest algorithm uses a tree ensemble learning algorithm that, through the selection of the best split and the repeated combinations of trees, helps to generalize better than single decision trees; while the algorithms of boosting, named now XGBoost and LightGBM, work by improving weak classifiers in a sequential fashion so to reduce the error. On the other hand, document ranking and biomedical text classification were the areas these methods were primarily applied in the structured text data applications. Despite their advantages, these procedures heavily depend on the feature engineering and can be found tricky if the data is sequential and context-sensitive.</p></div></div></div><div class="el-h3 heading-wrapper"><h3 data-heading="Deep Learning Methods" dir="auto" class="heading" id="Deep_Learning_Methods"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>Deep Learning Methods</h3><div class="heading-children"><div class="el-p"><p dir="auto">Despite the traditional ML techniques, deep learning (DL) methods have altered text classification by obtaining feature representations from the text itself instead of hand-crafting them. With the introduction of FastText by Facebook, a simple yet effective machine learning algorithm for text categorization has been developed. It reflects words as dense vectors (word embeddings) and averages them to create document representational vectors. Furthermore, subword modeling helps to tolerate spelling mistakes and morphological variants, which are frequent in the case of low-resource languages. The downside of FastText is its straightforward approach, which may be a drawback when it comes to complex relationships between words.</p></div><div class="el-p"><p dir="auto">Recurrent Neural Networks (RNNs) and their variations, such as Long Short-Term Memory (LSTM) networks, have incorporated sequential modeling capabilities into text categorization. LSTMs somewhat mitigate the vanishing gradient problem existing in conventional RNNs and maintain long-term dependencies. Consequently, they are viable candidates for applications which call for context comprehension, such as sentiment analysis or question-answering tasks. On the other side, RNNs and LSTMs read texts one after another, which elaborates on performance and the cost of computation and the time of training for big data or long sequences.</p></div><div class="el-p"><p dir="auto">CNNs, developed primarily for image processing, have also demonstrated their capacity of being employed for text classification. In this way, by treating sentences as one-dimensional sequences where local features are extracted – these features can be n-grams via convolutional filters. Thus, they are probably the best in this class where it's essential to consider the local context, i.e., short text classification or sentiment analysis. CNNs are more efficient computationally, achieving increased parallel processing, yet they may still struggle to encode hints of long-term text dependencies.</p></div><div class="el-p"><p dir="auto">The development that caused the greatest disruption in the text classification concept was through Transformer-based models, especially BERT, which is the Bidirectional Encoder Representations from Transformers. BERT introduced a new type of language modeling and used the transformer architecture which is self-attentional mechanisms. Differently from the previous models, BERT unifies the initial context with opposite directions, which results in a more profound knowledge of the relations within a sentence. BERT proves to be the most efficient model for various NLP tasks, such as text classification, sentiment analysis, and Named Entity Recognition (NER), by virtue that it has been pretrained on a huge dataset. It has an enormous capacity for consecutive learning and retraining, so it has become one of the most applicable models. Nevertheless, the model's weight and the high requirements of computational loads prevent small organizations and low-lifting environments from having visible results.</p></div><div class="el-p"><p dir="auto">While ML methods such as MNB and SVM provide computational simplicity and efficiency, they still hugely depend on feature engineering and therefore tend to lose semantics and contextuality. In contrast, the DL approach, in particular that of transformer-based models, like BERT, champions this but it requires enormous computation power and huge amount of data for training. Accordingly, the methodology employed is often tailored to the task characteristics, like size of data, computation resources, and level of the text complexity. The combination of classical ML techniques and the recent innovations in DL methods have greatly extended the research horizons of text analysis, making the text classification area more dynamic and captivating.</p></div><div class="el-table" dir="ltr" style="overflow-x: auto;"><table>
<thead>
<tr>
<th dir="ltr"><strong>Method</strong></th>
<th dir="ltr"><strong>Advantages</strong></th>
<th dir="ltr"><strong>Limitations</strong></th>
<th dir="ltr"><strong>Best Use Cases</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td dir="ltr">Multinomial Naive Bayes</td>
<td dir="ltr">Simple, fast, effective for small datasets</td>
<td dir="ltr">Independence assumption may not hold</td>
<td dir="ltr">Spam filtering, basic sentiment analysis</td>
</tr>
<tr>
<td dir="ltr">Support Vector Machines</td>
<td dir="ltr">Works well with high-dimensional data</td>
<td dir="ltr">Computationally intensive for large datasets</td>
<td dir="ltr">Review categorization, topic modeling</td>
</tr>
<tr>
<td dir="ltr">Random Forest</td>
<td dir="ltr">Handles noisy and imbalanced data</td>
<td dir="ltr">Limited interpretability, not optimal for sparse data</td>
<td dir="ltr">Biomedical text classification, domain-specific tasks</td>
</tr>
<tr>
<td dir="ltr">Logistic Regression</td>
<td dir="ltr">Easy to implement and interpret</td>
<td dir="ltr">Fails on non-linear relationships</td>
<td dir="ltr">Benchmarking, small-scale applications</td>
</tr>
<tr>
<td dir="ltr">FastText</td>
<td dir="ltr">Fast and scalable, robust to misspellings</td>
<td dir="ltr">Does not capture long-range dependencies</td>
<td dir="ltr">Low-resource or domain-specific tasks</td>
</tr>
<tr>
<td dir="ltr">LSTM</td>
<td dir="ltr">Captures sequential dependencies, suitable for long texts</td>
<td dir="ltr">Slow training, struggles with very long sequences</td>
<td dir="ltr">Sentiment analysis, question answering</td>
</tr>
<tr>
<td dir="ltr">textCNN</td>
<td dir="ltr">Efficient, captures n-gram features effectively</td>
<td dir="ltr">Fails to model long-term dependencies</td>
<td dir="ltr">News classification, short text classification</td>
</tr>
<tr>
<td dir="ltr">BERT and Variants</td>
<td dir="ltr">State-of-the-art accuracy, handles long texts with global context</td>
<td dir="ltr">High computational cost, requires large-scale pretraining</td>
<td dir="ltr">High-stakes tasks like medical or legal text classification</td>
</tr>
</tbody>
</table></div></div></div></div></div><div class="el-h2 heading-wrapper"><h2 data-heading="Methodology" dir="auto" class="heading" id="Methodology"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>Methodology</h2><div class="heading-children"><div class="el-p"><p dir="auto"><span alt="workflow.png" src="workflow.png" class="internal-embed media-embed image-embed is-loaded"><img alt="workflow.png" src="data-analysis/big-data-analysis/peoject/workflow.png"></span></p></div><div class="el-p"><p dir="auto">The entire process is structured as follows:</p></div><div class="el-ol"><ol>
<li data-line="0" dir="auto">Input text undergoes sensitive word matching and FastText screening.</li>
<li data-line="1" dir="auto">Texts flagged by both methods are classified as <strong>illegal</strong>.</li>
<li data-line="2" dir="auto">Conflicting cases are resolved by the BERT classification model.</li>
<li data-line="3" dir="auto">Non-illegal texts proceed to the high-quality comment filtering stage.</li>
<li data-line="4" dir="auto">Token embeddings are generated using pretrained BERT.</li>
<li data-line="5" dir="auto">An Auto-Encoder calculates reconstruction error to assess quality.</li>
<li data-line="6" dir="auto">Texts with acceptable reconstruction errors are deemed <strong>high-quality comments</strong>.</li>
</ol></div><div class="el-p"><p dir="auto">The proposed system consists of two main components: <strong>illegal text detection</strong> and <strong>high-quality comment filtering</strong>, designed to operate sequentially for robust content moderation. Each component is trained and evaluated independently, ensuring flexibility and scalability. Below, we describe the methodology for each stage in detail.</p></div><div class="el-h3 heading-wrapper"><h3 data-heading="1. Illegal Text Detection" dir="auto" class="heading" id="1._Illegal_Text_Detection"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>1. Illegal Text Detection</h3><div class="heading-children"><div class="el-p"><p dir="auto">The first stage is illegal text detection, which acts as a filtering point. The goal is to explore the way of finding and classifying the texts with the sensitive or illegal information. This hybrid stage combines rules-based systems and machine learning for a better precision.</p></div><div class="el-ul"><ul>
<li data-line="0" dir="auto">
<p><strong>Sensitive Word Matching:</strong><br>
The text is analyzed, being driven by employed rules, via a sensitive term-matching approach. There exists a given set of illegal or sensitive vocabulary that is employed to flag text that contains this vocabulary. Such an approach is computationally efficient and interpretable. However, it may generate spurious results or fail to find texts that have different wording but similar expressions. </p>
</li>
<li data-line="3" dir="auto">
<p><strong>FastText Model Screening:</strong><br>
At the same time, the input is fed to the new model, named FastText. Developed as a lightweight deep learning model employed by Facebook, it consists of a combination of word embeddings, representing text, as well as the ability to efficiently predict the probability of a piece of text being illegal. This characteristic will help maintain a stable position in spite of spelling variations and slight modifications of the text.</p>
</li>
<li data-line="6" dir="auto"><div class="list-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>
<p><strong>Fusion of Results:</strong><br>
To add another reliability supporting factor, the system adopts the output from both the sensitive word match and FastText screening methods. The decision algorithm can be explained this way:</p>
<ul>
<li data-line="9" dir="auto">If both methods flag the text as illegal, it is directly classified as <strong>illegal</strong>.</li>
<li data-line="10" dir="auto">If both methods agree that the text is not illegal, it is passed to the next stage for high-quality filtering.</li>
<li data-line="11" dir="auto">If the results conflict (e.g., one flags illegal and the other does not), a <strong>BERT-based classification model</strong> is invoked to make the final determination.</li>
</ul>
</li>
<li data-line="13" dir="auto">
<p><strong>BERT Model for Conflict Resolution:</strong><br>
The BERT (Bidirectional Encoder Representations from Transformers) model leverages its deep contextual understanding of the text to resolve conflicts. BERT generates a bidirectional representation of the input text and uses fine-tuning to classify whether the text is illegal or not. This step adds a layer of robustness, particularly for texts with ambiguous or context-dependent content.</p>
</li>
</ul></div></div></div><div class="el-h3 heading-wrapper"><h3 data-heading="2. High-Quality Comment Filtering" dir="auto" class="heading" id="2._High-Quality_Comment_Filtering"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>2. High-Quality Comment Filtering</h3><div class="heading-children"><div class="el-p"><p dir="auto">For texts classified as <strong>non-illegal</strong> by the previous stage, the system proceeds to evaluate their quality through the <strong>high-quality comment filtering</strong> process. This stage involves the use of a <strong>pretrained BERT model</strong> for token embedding generation and an <strong>Auto-Encoder</strong> for reconstruction-based quality assessment.</p></div><div class="el-ul"><ul>
<li data-line="0" dir="auto"><strong>Token Embeddings Generation with BERT:</strong><br>
The input text is first tokenized and converted into token embeddings using a pretrained BERT model. The [CLS] token, which serves as an aggregate representation of the entire text, is also included in the matrix. The output is a multi-dimensional matrix where each row corresponds to the embedding of a token in the input sequence. This representation captures both semantic and syntactic information from the text.<br>
</li>
<li data-line="3" dir="auto"><div class="list-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><strong>Auto-Encoder Reconstruction:</strong><br>
The BERT-generated token embeddings are fed into a <strong>trained Auto-Encoder</strong>, a type of neural network used for unsupervised learning. The Auto-Encoder architecture consists of:
<ul>
<li data-line="6" dir="auto"><strong>Encoder:</strong> Compresses the high-dimensional input embeddings into a latent-space representation, reducing noise and dimensionality.</li>
<li data-line="7" dir="auto"><strong>Decoder:</strong> Reconstructs the input embeddings from the latent representation, aiming to minimize the reconstruction error.</li>
</ul>
</li>
<li data-line="8" dir="auto"><strong>Reconstruction Error Calculation:</strong><br>
After processing the embeddings, the system calculates the <strong>reconstruction error</strong> between the original input embeddings and the reconstructed output. The reconstruction error serves as a measure of how well the text aligns with the characteristics of high-quality comments. The rationale is that high-quality texts are more likely to be accurately reconstructed due to their alignment with the training data patterns.<br>
</li>
<li data-line="11" dir="auto"><div class="list-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><strong>Quality Determination:</strong><br>
The system applies a predefined threshold to the reconstruction error:
<ul>
<li data-line="14" dir="auto">If the error falls <strong>within the acceptable range</strong>, the text is classified as a <strong>high-quality comment</strong>.</li>
<li data-line="15" dir="auto">If the error exceeds the threshold, the text is discarded, as it does not meet the quality standards.</li>
</ul>
</li>
</ul></div><div class="el-p"><p dir="auto">This comprehensive two-stage pipeline ensures robust filtering of illegal content while simultaneously identifying high-quality comments for further use. By combining rule-based methods, traditional deep learning (FastText), and advanced transformer-based techniques (BERT), the system achieves a balance of efficiency, accuracy, and scalability.</p></div></div></div></div></div><div class="el-h2 heading-wrapper"><h2 data-heading="Experimental study and Result analysis" dir="auto" class="heading" id="Experimental_study_and_Result_analysis"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>Experimental study and Result analysis</h2><div class="heading-children"><div class="el-h3 heading-wrapper"><h3 data-heading="Illegal Text Detection: Experimental Results and Model Selection" dir="auto" class="heading" id="Illegal_Text_Detection:_Experimental_Results_and_Model_Selection"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>Illegal Text Detection: Experimental Results and Model Selection</h3><div class="heading-children"><div class="el-p"><p dir="auto">In our project, we conducted extensive experiments to evaluate the performance of <strong>Machine Learning (ML)</strong> and <strong>Deep Learning (DL)</strong> models for illegal text detection. The results demonstrate that <strong>Deep Learning methods</strong> significantly outperform traditional ML approaches, leading to the selection of a two-stage hybrid approach combining <strong>FastText</strong> and <strong>BERT</strong>. This strategy achieves a balance between computational efficiency and classification accuracy.</p></div><div class="el-h4 heading-wrapper"><h4 data-heading="Experimental Results" dir="auto" class="heading" id="Experimental_Results"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><strong>Experimental Results</strong></h4><div class="heading-children"><div class="el-p"><p dir="auto">The evaluation metrics for both ML and DL models, including <strong>Accuracy</strong>, <strong>Precision</strong>, <strong>Recall</strong>, and <strong>F1-Score</strong>, are presented in the following tables:</p></div><div class="el-p"><p dir="auto"><strong>Machine Learning Models Performance</strong></p></div><div class="el-table" dir="ltr" style="overflow-x: auto;"><table>
<thead>
<tr>
<th dir="ltr"><strong>Model</strong></th>
<th dir="ltr"><strong>Accuracy</strong></th>
<th dir="ltr"><strong>Precision</strong></th>
<th dir="ltr"><strong>Recall</strong></th>
<th dir="ltr"><strong>F1-Score</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td dir="ltr">MultinomialNB</td>
<td dir="auto">0.5461</td>
<td dir="auto">0.5427</td>
<td dir="auto">0.5461</td>
<td dir="auto">0.5441</td>
</tr>
<tr>
<td dir="ltr">Random Forest</td>
<td dir="auto">0.5899</td>
<td dir="auto">0.5905</td>
<td dir="auto">0.5899</td>
<td dir="auto">0.4942</td>
</tr>
<tr>
<td dir="ltr">XGBoost</td>
<td dir="auto">0.5847</td>
<td dir="auto">0.5672</td>
<td dir="auto">0.5847</td>
<td dir="auto">0.5165</td>
</tr>
<tr>
<td dir="ltr">LightGBM</td>
<td dir="auto">0.5784</td>
<td dir="auto">0.5548</td>
<td dir="auto">0.5784</td>
<td dir="auto">0.5086</td>
</tr>
<tr>
<td dir="ltr">SVM</td>
<td dir="auto">0.5680</td>
<td dir="auto">0.5491</td>
<td dir="auto">0.5680</td>
<td dir="auto">0.5423</td>
</tr>
<tr>
<td dir="ltr">Logistic Regression</td>
<td dir="auto">0.5600</td>
<td dir="auto">0.5413</td>
<td dir="auto">0.5600</td>
<td dir="auto">0.5375</td>
</tr>
</tbody>
</table></div><div class="el-p"><p dir="auto"><strong>Deep Learning Models Performance</strong></p></div><div class="el-table" dir="ltr" style="overflow-x: auto;"><table>
<thead>
<tr>
<th dir="ltr"><strong>Model</strong></th>
<th dir="ltr"><strong>Accuracy</strong></th>
<th dir="ltr"><strong>Precision</strong></th>
<th dir="ltr"><strong>Recall</strong></th>
<th dir="ltr"><strong>F1-Score</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td dir="ltr">FastText</td>
<td dir="auto">0.99</td>
<td dir="auto">0.99</td>
<td dir="auto">0.985</td>
<td dir="auto">0.985</td>
</tr>
<tr>
<td dir="ltr">BERT</td>
<td dir="auto">0.99</td>
<td dir="auto">0.985</td>
<td dir="auto">0.99</td>
<td dir="auto">0.99</td>
</tr>
<tr>
<td dir="ltr">LSTM</td>
<td dir="auto">0.99</td>
<td dir="auto">0.99</td>
<td dir="auto">0.985</td>
<td dir="auto">0.99</td>
</tr>
<tr>
<td dir="ltr">TextCNN</td>
<td dir="auto">0.98</td>
<td dir="auto">0.985</td>
<td dir="auto">0.985</td>
<td dir="auto">0.985</td>
</tr>
</tbody>
</table></div><div class="el-p"><p dir="auto">From these results, we observe the following:</p></div><div class="el-ul"><ul>
<li data-line="0" dir="auto"><strong>Deep Learning models</strong> like BERT, LSTM, and FastText achieve near-perfect accuracy and F1-scores (~0.99), far outperforming traditional ML methods.</li>
<li data-line="1" dir="auto">Among ML methods, <strong>Random Forest</strong> achieves the highest accuracy (0.5899), but the overall F1-scores remain relatively low (&lt;0.55), indicating limitations in capturing complex textual patterns.</li>
<li data-line="2" dir="auto">While BERT achieves the highest performance, its computational cost makes it less efficient for large-scale text filtering.</li>
</ul></div></div></div><div class="el-h4 heading-wrapper"><h4 data-heading="Model Selection: Two-Stage Hybrid Approach" dir="auto" class="heading" id="Model_Selection:_Two-Stage_Hybrid_Approach"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>Model Selection: Two-Stage Hybrid Approach</h4><div class="heading-children"><div class="el-p"><p dir="auto">Considering the experimental results, we adopted the two-stage hybrid model, which consists of FastText and BERT, suitable for illegal text detection. This is done by benefiting from the strong features of both approaches.</p></div><div class="el-ol"><ol>
<li data-line="0" dir="auto">
<p>FastText for Initial Filtering:<br>
Yes. One prominent advantage of using FastText for initial text filtering is that it allows for extremely fast text processing. Thus, it is very bloodthirsty when it comes to time utilization and resources. It categorizes big pieces of input texts into "most likely" illegal or "most likely" non-illegal segments. FastText, on the other hand, runs through a large chunk of the data at once, which makes the computational process lighter on the next model.</p>
</li>
<li data-line="3" dir="auto">
<p>BERT for Final Decision-Making:<br>
Mention of texts that seem ambiguous or seem illegal would be processed by BERT for further analysis. Precision of sentiment classification is guaranteed by BERT, even in the most ambiguous or borderline cases, because BERT utilizes deep contextual understanding.</p>
</li>
</ol></div></div></div><div class="el-h4 heading-wrapper"><h4 data-heading="Workflow of the Two-Stage Approach" dir="auto" class="heading" id="Workflow_of_the_Two-Stage_Approach"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>Workflow of the Two-Stage Approach</h4><div class="heading-children"><div class="el-ol"><ol>
<li data-line="0" dir="auto">Non-suspicious content appears to be filtered through FastText rather than being analyzed using other techniques like, for example, k-nearest neighbors.</li>
<li data-line="1" dir="auto">FastText recognizer shown sections that are either "probably illegal" or have mixed readings are examined in further detail using BERT.</li>
<li data-line="2" dir="auto">The last statement of BERT determines the final classification and takes into account all logical facts and other aspects.</li>
</ol></div><div class="el-p"><p dir="auto">Computational efficiency helps because most of the texts with trivial information will be filtered out during BERT's initial stages, and thus, the workload for BERT will be significantly reduced.</p></div><div class="el-p"><p dir="auto">High accuracy: Text detection using BERT is highly accurate, meaning it minimizes the number of false positives and overlapses of illegal contents.</p></div><div class="el-p"><p dir="auto">Scalability: This hybrid method is applicable in a variety of highly business-critical real-time scenarios, which need concurrent high throughput and low latency.</p></div><div class="el-p"><p dir="auto">A balanced trade-off: The proposed system employs the dual strategy of combining fastness (FastText) with robustness (BERT) to achieve optimal performance in the case of large-scale text detection problems.</p></div><div class="el-p"><p dir="auto">We arrive at a solution which is the hybrid of FastText and BERT, which allows us to achieve optimal balance between computational efficiency and classification precision for real-world applications requiring a combination of both speed and accuracy.</p></div></div></div></div></div><div class="el-h3 heading-wrapper"><h3 data-heading="High-Quality Comment Filtering: Reconstruction Error Analysis" dir="auto" class="heading" id="High-Quality_Comment_Filtering:_Reconstruction_Error_Analysis"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>High-Quality Comment Filtering: Reconstruction Error Analysis</h3><div class="heading-children"><div class="el-p"><p dir="auto">This section details the <strong>Auto-Encoder architecture</strong> used for filtering high-quality comments and provides an analysis of its experimental results, including <strong>training performance</strong> and <strong>reconstruction error evaluation</strong>.</p></div><div class="el-h4 heading-wrapper"><h4 data-heading="Model Architecture" dir="auto" class="heading" id="Model_Architecture"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>Model Architecture</h4><div class="heading-children"><div class="el-p"><p dir="auto">The Auto-Encoder consists of two main components: an <strong>Encoder</strong> and a <strong>Decoder</strong>. The architecture is designed to compress and reconstruct input text embeddings generated by <strong>BERT</strong>. The detailed configuration is as follows:</p></div><div class="el-ul"><ul>
<li data-line="0" dir="auto"><div class="list-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><strong>Encoder</strong>:
<ul>
<li data-line="1" dir="auto">Composed of <strong>2 fully connected layers</strong> activated by <strong>ReLU</strong>.</li>
<li data-line="2" dir="auto">Reduces the dimensionality of input embeddings into a <strong>compressed representation vector</strong> of size <strong>32 dimensions</strong>.</li>
</ul>
</li>
<li data-line="3" dir="auto"><div class="list-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><strong>Decoder</strong>:
<ul>
<li data-line="4" dir="auto">Symmetrically mirrors the encoder with <strong>2 fully connected layers</strong> activated by <strong>ReLU</strong>.</li>
<li data-line="5" dir="auto">Reconstructs the original input embeddings from the compressed vector.</li>
</ul>
</li>
<li data-line="6" dir="auto"><strong>Input Representation</strong>:<br>
Text data is tokenized and embedded into a matrix format using <strong>BERT token embeddings</strong>, capturing both semantic and syntactic features. The Auto-Encoder then learns to reconstruct the input embeddings.</li>
</ul></div><div class="el-p"><p dir="auto"><span alt="Auto-encoder-loss.png" src="Auto-encoder-loss.png" class="internal-embed media-embed image-embed is-loaded"><img alt="Auto-encoder-loss.png" src="data-analysis/big-data-analysis/peoject/auto-encoder-loss.png"></span></p></div><div class="el-p"><p dir="auto">Training and Validation Loss: The curves of the training and validation loss validate that the Auto-Encoder accomplishes convergence for 200 epochs. The losses drop drastically in the first epochs, with a further drop to about 0.1 at the end, showing that optimal learning of the embeddings takes place, resulting in the small error achieved.</p></div><div class="el-ul"><ul>
<li data-line="0" dir="auto">Observations:</li>
<li data-line="1" dir="auto">Training loss (blue) and validation loss (orange) are indicating a monotonically decreasing curve without significant overfitting, thereby resulting in a noticeable improvement of the overall model performance.</li>
<li data-line="2" dir="auto">The minuscule discrepancy between training and validation loss substantiates strong generalization.</li>
</ul></div><div class="el-p"><p dir="auto"><span alt="Auto-encoder-Distribution.png" src="Auto-encoder-Distribution.png" class="internal-embed media-embed image-embed is-loaded"><img alt="Auto-encoder-Distribution.png" src="data-analysis/big-data-analysis/peoject/auto-encoder-distribution.png"></span></p></div><div class="el-p"><p dir="auto">Reconstruction Error Distribution: The distribution of reconstruction error would provide knowledge of the system inquiring whether it can make proper division between high-quality comments and low-quality comments. The histogram below highlights key observations:</p></div><div class="el-ul"><ul>
<li data-line="0" dir="auto">Reconstruction Error Threshold:<br>
A red dashed line at the 95th percentile of the reconstruction error distribution would be used as a cutoff for discriminating between normal and abnormal reconstructions. Comments with mistakes below the threshold are determined as being of higher quality, while those that are over the threshold are considered defective.</li>
<li data-line="2" dir="auto">Error Distribution:<br>
Many comments fit the 0.50-0.55 range of reconstruction errors, which supports the claim that the model can reconstruct high-quality content. In contrast, a small set of comments with reconstruction errors above 0.56 show low quality, as they deviate from the learned latent representations.</li>
</ul></div></div></div></div></div></div></div><div class="el-h2 heading-wrapper"><h2 data-heading="Future work and conclusion" dir="auto" class="heading" id="Future_work_and_conclusion"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>Future work and conclusion</h2><div class="heading-children"><div class="el-h3 heading-wrapper"><h3 data-heading="Validation of Effectiveness" dir="auto" class="heading" id="Validation_of_Effectiveness"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>Validation of Effectiveness</h3><div class="heading-children"><div class="el-p"><p dir="auto">Since the current system operates with an <strong>unsupervised model</strong> for high-quality comment filtering, it is challenging to directly verify its effectiveness without labeled data. This limitation creates a gap in understanding how well the Auto-Encoder distinguishes between high- and low-quality comments in practical use cases.</p></div><div class="el-ul"><ul>
<li data-line="0" dir="auto"><strong>Possible Solution:</strong><br>
To address this, the system can be deployed in a <strong>real-world application environment</strong> where user interaction and behavior are monitored. <strong>User feedback</strong> can be collected to evaluate the system's accuracy and reliability. Metrics such as user satisfaction rates, content retention rates, and manual moderation corrections can serve as indicators of the model's effectiveness. Combining this feedback with semi-supervised fine-tuning on partially labeled datasets can further enhance validation.</li>
</ul></div></div></div><div class="el-h3 heading-wrapper"><h3 data-heading="Improving the Auto-Encoder Architecture" dir="auto" class="heading" id="Improving_the_Auto-Encoder_Architecture"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>Improving the Auto-Encoder Architecture</h3><div class="heading-children"><div class="el-p"><p dir="auto">The Auto-Encoder, as it is shaped at present, saturates full-connected layers for both its encoder and decoder placement. While the framework is made of simple anatomy, there is a great chance of not embracing all the complex relationships and patterns existing in the texts, especially in cases like lengthy and very intricate formats. The following improvements are proposed:</p></div><div class="el-ol"><ol>
<li data-line="0" dir="auto">
<p><strong>Inclusion of Convolution Layer:</strong><br>
The convolutional layers that can be integrated into the Auto-encoder model have the potential to strengthen its ability to identify spatial and temporal relationships among the token representations. Due to their efficacy in recognizing n-gram features and local dependencies in texts, the convolutional layers can contribute to obtaining more accurate content reconstruction and a better differentiation of a low or high-quality content.</p>
</li>
<li data-line="3" dir="auto">
<p><strong>Utilizing Transformer-Based Architectures:</strong><br>
Build on Transformer-based architectures like BERT and GPT using advanced methods from the latest NLP tools for fine-tuning the Auto-Encoder. Through the application of self-attention methods, Transformers can obtain global context as well as long-range dependencies between objects in the sequences involved. I intend to use this method, which will steer me to a more in-depth feature extraction that is capable of closer semantic reasoning.</p>
</li>
<li data-line="6" dir="auto">
<p><strong>Incorporating Variational Autoencoders (VAEs):</strong><br>
Variational Auto-Encoder (VAE) can be the best solution given it is capable of generalizing and can also reveal latent designs in the data. This feature is an improvement on traditional Auto-Encoders as they introduce a probabilistic distribution in the latent space, which allows the model to plan and model better the actual textual patterns specifically for the variations. This form of refinement will, away, allow the system to have an easy time handling noise or ambiguity of the input while also increasing the quality of reconstruction.</p>
</li>
<li data-line="9" dir="auto">
<p><strong>Hybrid Models with Attention Mechanisms:</strong><br>
Importing attention into Auto-Encoder and putting them in together can lead to lower attention on less important tokens or features than on the more important ones within the reconstruction process. Attention filters of this kind, which are present in the Transformers, make the model focus on the priorities of the text parts against the importance of each part, which brings on the more regards-based exactness and era-based reconstructions.</p>
</li>
</ol></div></div></div><div class="el-h3 heading-wrapper"><h3 data-heading="Future Experiments and Evaluation" dir="auto" class="heading" id="Future_Experiments_and_Evaluation"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>Future Experiments and Evaluation</h3><div class="heading-children"><div class="el-p"><p dir="auto">To validate the proposed improvements, the following steps can be undertaken:</p></div><div class="el-ul"><ul>
<li data-line="0" dir="auto">
<p>Benchmarking Architectures: Carry out trials where the new Auto-Encoder architectures (such as convolutional Auto-Encoders, Transformer-based Auto-Encoders, and VAEs) are juxtaposed against the existing ones and evaluate their performance. For evaluation, metrics like reconstruction error, precision, recall, and F1 score could be used as indicators.</p>
</li>
<li data-line="2" dir="auto">
<p>Data Augmentation: Employ data augmentation strategies to create a set of different versions, both high- and low-quality, to be used in training and testing. Techniques like back-translation, paraphrasing, and noise injection have proved effective in producing robust models.</p>
</li>
<li data-line="4" dir="auto">
<p>Semi-Supervised Learning: Evaluate semi-supervised methods, which can utilize a small labeled dataset to aid in the generalization of being supervised by what is being learned. A method of using pseudo-labeling and consistency regularization can be applied as a consistency to improve the model's prediction.</p>
</li>
<li data-line="6" dir="auto">
<p>Human-in-the-Loop Validation: Add human moderators to the system and evaluate human comment filtration to assess the quality of the filtered comments. Continuous and repeatable feedback loop could be used for tuning the model and aligning it with real-world expectations.</p>
</li>
</ul></div><div class="el-p"><p dir="auto">Consequently, enhancement measures will strengthen the system to enable it to handle illegal text detection and filtering of quality comments effectively. The integrated form of modern architectures and real-time validation will surely eliminate existing boundaries and facilitate system capabilities.</p></div></div></div></div></div><div class="el-h2 heading-wrapper"><h2 data-heading="References" dir="auto" class="heading" id="References"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>References</h2><div class="heading-children"><div class="el-ol"><ol>
<li data-line="0" dir="auto">Bojanowski, P., Grave, E., Joulin, A., &amp; Mikolov, T. (2017). Enriching word vectors with subword information. <em>Transactions of the Association for Computational Linguistics, 5</em>, 135–146. <a rel="noopener nofollow" class="external-link" href="https://arxiv.org/abs/1607.04606" target="_blank">https://arxiv.org/abs/1607.04606</a></li>
<li data-line="2" dir="auto">Devlin, J., Chang, M. W., Lee, K., &amp; Toutanova, K. (2019). BERT: Pre-training of deep bidirectional transformers for language understanding. In <em>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em>. <a rel="noopener nofollow" class="external-link" href="https://arxiv.org/abs/1810.04805" target="_blank">https://arxiv.org/abs/1810.04805</a></li>
<li data-line="4" dir="auto">Hinton, G. E., &amp; Salakhutdinov, R. R. (2006). Reducing the dimensionality of data with neural networks. <em>Science, 313</em>(5786), 504–507. <a rel="noopener nofollow" class="external-link" href="https://doi.org/10.1126/science.1127647" target="_blank">https://doi.org/10.1126/science.1127647</a></li>
<li data-line="6" dir="auto">Hochreiter, S., &amp; Schmidhuber, J. (1997). Long short-term memory. <em>Neural Computation, 9</em>(8), 1735–1780. <a rel="noopener nofollow" class="external-link" href="https://doi.org/10.1162/neco.1997.9.8.1735" target="_blank">https://doi.org/10.1162/neco.1997.9.8.1735</a></li>
<li data-line="8" dir="auto">Kim, Y. (2014). Convolutional neural networks for sentence classification. In <em>Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>. <a rel="noopener nofollow" class="external-link" href="https://arxiv.org/abs/1408.5882" target="_blank">https://arxiv.org/abs/1408.5882</a></li>
<li data-line="10" dir="auto">Cortes, C., &amp; Vapnik, V. (1995). Support-vector networks. <em>Machine Learning, 20</em>(3), 273–297. <a rel="noopener nofollow" class="external-link" href="https://doi.org/10.1007/BF00994018" target="_blank">https://doi.org/10.1007/BF00994018</a></li>
<li data-line="12" dir="auto">Breiman, L. (2001). Random forests. <em>Machine Learning, 45</em>(1), 5–32. <a rel="noopener nofollow" class="external-link" href="https://doi.org/10.1023/A:1010933404324" target="_blank">https://doi.org/10.1023/A:1010933404324</a></li>
<li data-line="14" dir="auto">Chen, T., &amp; Guestrin, C. (2016). XGBoost: A scalable tree boosting system. In <em>Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD)</em>. <a rel="noopener nofollow" class="external-link" href="https://arxiv.org/abs/1603.02754" target="_blank">https://arxiv.org/abs/1603.02754</a></li>
<li data-line="16" dir="auto">Kingma, D. P., &amp; Welling, M. (2014). Auto-encoding variational Bayes. In <em>Proceedings of the 2nd International Conference on Learning Representations (ICLR)</em>. <a rel="noopener nofollow" class="external-link" href="https://arxiv.org/abs/1312.6114" target="_blank">https://arxiv.org/abs/1312.6114</a></li>
<li data-line="18" dir="auto">Wei, J., &amp; Zou, K. (2019). EDA: Easy data augmentation techniques for boosting performance on text classification tasks. In <em>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing</em>. <a rel="noopener nofollow" class="external-link" href="https://arxiv.org/abs/1901.11196" target="_blank">https://arxiv.org/abs/1901.11196</a></li>
</ol></div><div class="mod-footer mod-ui"></div></div></div></div></div></div></div></div><div class="sidebar-right sidebar"><div class="sidebar-handle"></div><div class="sidebar-topbar"><div class="topbar-content"></div><div class="clickable-icon sidebar-collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><path d="M21 3H3C1.89543 3 1 3.89543 1 5V19C1 20.1046 1.89543 21 3 21H21C22.1046 21 23 20.1046 23 19V5C23 3.89543 22.1046 3 21 3Z"></path><path d="M10 4V20"></path><path d="M4 7H7"></path><path d="M4 10H7"></path><path d="M4 13H7"></path></svg></div></div><div class="sidebar-content"><div class="tree-container mod-root nav-folder tree-item outline-tree" data-depth="0"><div class="tree-header"><span class="sidebar-section-header">Table Of Contents</span><button class="clickable-icon collapse-tree-button" aria-label="Collapse All"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 20 20" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></svg></button></div><div class="tree-scroll-area tree-item-children nav-folder-children"><div class="tree-item mod-tree-folder nav-folder mod-collapsible is-collapsed" style="display: none;"></div><div class="tree-item" data-depth="1"><a class="tree-link" href="data-analysis/big-data-analysis/peoject/bda-project-report.html#BDA-Project-Report" data-path=""><div class="tree-item-contents heading-link" heading-name="BDA-Project-Report"><span class="tree-item-title">BDA-Project-Report</span></div></a><div class="tree-item-children nav-folder-children"><div class="tree-item" data-depth="2"><a class="tree-link" href="data-analysis/big-data-analysis/peoject/bda-project-report.html#Abstract" data-path=""><div class="tree-item-contents heading-link" heading-name="Abstract"><span class="tree-item-title">Abstract</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="2"><a class="tree-link" href="data-analysis/big-data-analysis/peoject/bda-project-report.html#Introduction" data-path=""><div class="tree-item-contents heading-link" heading-name="Introduction"><span class="tree-item-title">Introduction</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item mod-collapsible" data-depth="2"><a class="tree-link" href="data-analysis/big-data-analysis/peoject/bda-project-report.html#Related_works" data-path=""><div class="tree-item-contents heading-link" heading-name="Related works"><div class="collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><span class="tree-item-title">Related works</span></div></a><div class="tree-item-children nav-folder-children"><div class="tree-item" data-depth="3"><a class="tree-link" href="data-analysis/big-data-analysis/peoject/bda-project-report.html#Machine_Learning_Methods" data-path=""><div class="tree-item-contents heading-link" heading-name="Machine Learning Methods"><span class="tree-item-title">Machine Learning Methods</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="3"><a class="tree-link" href="data-analysis/big-data-analysis/peoject/bda-project-report.html#Deep_Learning_Methods" data-path=""><div class="tree-item-contents heading-link" heading-name="Deep Learning Methods"><span class="tree-item-title">Deep Learning Methods</span></div></a><div class="tree-item-children nav-folder-children"></div></div></div></div><div class="tree-item mod-collapsible" data-depth="2"><a class="tree-link" href="data-analysis/big-data-analysis/peoject/bda-project-report.html#Methodology" data-path=""><div class="tree-item-contents heading-link" heading-name="Methodology"><div class="collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><span class="tree-item-title">Methodology</span></div></a><div class="tree-item-children nav-folder-children"><div class="tree-item" data-depth="3"><a class="tree-link" href="data-analysis/big-data-analysis/peoject/bda-project-report.html#1._Illegal_Text_Detection" data-path=""><div class="tree-item-contents heading-link" heading-name="1. Illegal Text Detection"><span class="tree-item-title">1. 
Illegal Text Detection
</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="3"><a class="tree-link" href="data-analysis/big-data-analysis/peoject/bda-project-report.html#2._High-Quality_Comment_Filtering" data-path=""><div class="tree-item-contents heading-link" heading-name="2. High-Quality Comment Filtering"><span class="tree-item-title">2. 
High-Quality Comment Filtering
</span></div></a><div class="tree-item-children nav-folder-children"></div></div></div></div><div class="tree-item mod-collapsible" data-depth="2"><a class="tree-link" href="data-analysis/big-data-analysis/peoject/bda-project-report.html#Experimental_study_and_Result_analysis" data-path=""><div class="tree-item-contents heading-link" heading-name="Experimental study and Result analysis"><div class="collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><span class="tree-item-title">Experimental study and Result analysis</span></div></a><div class="tree-item-children nav-folder-children"><div class="tree-item mod-collapsible" data-depth="3"><a class="tree-link" href="data-analysis/big-data-analysis/peoject/bda-project-report.html#Illegal_Text_Detection:_Experimental_Results_and_Model_Selection" data-path=""><div class="tree-item-contents heading-link" heading-name="Illegal Text Detection: Experimental Results and Model Selection"><div class="collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><span class="tree-item-title">Illegal Text Detection: Experimental Results and Model Selection</span></div></a><div class="tree-item-children nav-folder-children"><div class="tree-item" data-depth="4"><a class="tree-link" href="data-analysis/big-data-analysis/peoject/bda-project-report.html#Experimental_Results" data-path=""><div class="tree-item-contents heading-link" heading-name="Experimental Results"><span class="tree-item-title">Experimental Results</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="4"><a class="tree-link" href="data-analysis/big-data-analysis/peoject/bda-project-report.html#Model_Selection:_Two-Stage_Hybrid_Approach" data-path=""><div class="tree-item-contents heading-link" heading-name="Model Selection: Two-Stage Hybrid Approach"><span class="tree-item-title">Model Selection: Two-Stage Hybrid Approach</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="4"><a class="tree-link" href="data-analysis/big-data-analysis/peoject/bda-project-report.html#Workflow_of_the_Two-Stage_Approach" data-path=""><div class="tree-item-contents heading-link" heading-name="Workflow of the Two-Stage Approach"><span class="tree-item-title">Workflow of the Two-Stage Approach</span></div></a><div class="tree-item-children nav-folder-children"></div></div></div></div><div class="tree-item mod-collapsible" data-depth="3"><a class="tree-link" href="data-analysis/big-data-analysis/peoject/bda-project-report.html#High-Quality_Comment_Filtering:_Reconstruction_Error_Analysis" data-path=""><div class="tree-item-contents heading-link" heading-name="High-Quality Comment Filtering: Reconstruction Error Analysis"><div class="collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><span class="tree-item-title">High-Quality Comment Filtering: Reconstruction Error Analysis</span></div></a><div class="tree-item-children nav-folder-children"><div class="tree-item" data-depth="4"><a class="tree-link" href="data-analysis/big-data-analysis/peoject/bda-project-report.html#Model_Architecture" data-path=""><div class="tree-item-contents heading-link" heading-name="Model Architecture"><span class="tree-item-title">Model Architecture</span></div></a><div class="tree-item-children nav-folder-children"></div></div></div></div></div></div><div class="tree-item mod-collapsible" data-depth="2"><a class="tree-link" href="data-analysis/big-data-analysis/peoject/bda-project-report.html#Future_work_and_conclusion" data-path=""><div class="tree-item-contents heading-link" heading-name="Future work and conclusion"><div class="collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><span class="tree-item-title">Future work and conclusion</span></div></a><div class="tree-item-children nav-folder-children"><div class="tree-item" data-depth="3"><a class="tree-link" href="data-analysis/big-data-analysis/peoject/bda-project-report.html#Validation_of_Effectiveness" data-path=""><div class="tree-item-contents heading-link" heading-name="Validation of Effectiveness"><span class="tree-item-title">Validation of Effectiveness</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="3"><a class="tree-link" href="data-analysis/big-data-analysis/peoject/bda-project-report.html#Improving_the_Auto-Encoder_Architecture" data-path=""><div class="tree-item-contents heading-link" heading-name="Improving the Auto-Encoder Architecture"><span class="tree-item-title">Improving the Auto-Encoder Architecture</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="3"><a class="tree-link" href="data-analysis/big-data-analysis/peoject/bda-project-report.html#Future_Experiments_and_Evaluation" data-path=""><div class="tree-item-contents heading-link" heading-name="Future Experiments and Evaluation"><span class="tree-item-title">Future Experiments and Evaluation</span></div></a><div class="tree-item-children nav-folder-children"></div></div></div></div><div class="tree-item" data-depth="2"><a class="tree-link" href="data-analysis/big-data-analysis/peoject/bda-project-report.html#References" data-path=""><div class="tree-item-contents heading-link" heading-name="References"><span class="tree-item-title">References</span></div></a><div class="tree-item-children nav-folder-children"></div></div></div></div></div></div></div><script defer="">let rs = document.querySelector(".sidebar-right"); rs.classList.add("is-collapsed"); if (window.innerWidth > 768) rs.classList.remove("is-collapsed"); rs.style.setProperty("--sidebar-width", localStorage.getItem("sidebar-right-width"));</script></div></div></body></html>